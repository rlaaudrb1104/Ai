{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rlaaudrb1104/Ai/blob/WOOK/GraphCodeBERT_%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install tokenizers\n",
        "!pip install pandas\n",
        "!pip install torch\n",
        "!pip install tqdm\n",
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onNmXyNHZ7CY",
        "outputId": "74c4336e-df0d-4f96-9630-9c3b150dd66a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.2)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2024.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2I4SFwJZ7MJ",
        "outputId": "f5f59d63-5238-4664-cc5a-99fef591e94d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import RobertaTokenizer\n",
        "from tqdm.auto import tqdm\n",
        "import logging\n",
        "from torch.utils.data import DataLoader, SequentialSampler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.utils.data import DataLoader, RandomSampler\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import argparse\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "import pickle\n"
      ],
      "metadata": {
        "id": "WXDXFSr0uAr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 로깅 설정\n",
        "logger = logging.getLogger(__name__)\n",
        "logging.basicConfig(level=logging.INFO)"
      ],
      "metadata": {
        "id": "qPC6_DPcuCPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 인자 설정 클래스\n",
        "class Args:\n",
        "    train_data_file = '/content/drive/MyDrive/final_train2.csv'\n",
        "    eval_data_file = '/content/drive/MyDrive/final_val.csv'\n",
        "    test_data_file = '/content/drive/MyDrive/final_train2.csv'\n",
        "    output_dir = '/content/drive/My Drive/output'\n",
        "    model_name_or_path = 'microsoft/graphcodebert-base'\n",
        "    tokenizer_name = 'microsoft/graphcodebert-base'\n",
        "    block_size = 512\n",
        "\n",
        "args = Args()"
      ],
      "metadata": {
        "id": "Vx0Rjx1hc4Uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 토크나이저 설정\n",
        "tokenizer = RobertaTokenizer.from_pretrained(args.tokenizer_name)"
      ],
      "metadata": {
        "id": "g_VsNoT1uH1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# InputFeatures 클래스 정의\n",
        "class InputFeatures:\n",
        "    \"\"\"데이터의 한 세트의 특성을 정의합니다.\"\"\"\n",
        "    def __init__(self, input_ids, attention_mask, cwe_type_label):\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_mask = attention_mask\n",
        "        self.cwe_type_label = cwe_type_label\n"
      ],
      "metadata": {
        "id": "zEt6V2DbsqWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 특성 변환 함수\n",
        "def convert_examples_to_features(func, cwe_type_label, tokenizer, max_length):\n",
        "    \"\"\"코드 스니펫을 모델 입력에 적합한 특성으로 변환합니다.\"\"\"\n",
        "    encoding = tokenizer.encode_plus(\n",
        "        text=func,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_length,\n",
        "        pad_to_max_length=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt',\n",
        "        truncation=True\n",
        "    )\n",
        "    return InputFeatures(\n",
        "        input_ids=encoding['input_ids'].flatten(),\n",
        "        attention_mask=encoding['attention_mask'].flatten(),\n",
        "        cwe_type_label=cwe_type_label\n",
        "    )\n"
      ],
      "metadata": {
        "id": "2TviToGqm_3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TextDataset 클래스 정의\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, tokenizer, args, cwe_label_map, file_type=\"train\"):\n",
        "        file_path = getattr(args, f\"{file_type}_data_file\")\n",
        "        self.examples = []\n",
        "        df = pd.read_csv(file_path)\n",
        "        funcs = df[\"CODE\"].tolist()\n",
        "        cwe_type_labels = df[\"CWE ID\"].tolist()\n",
        "\n",
        "        for i in tqdm(range(len(funcs))):\n",
        "            cwe_type_label = cwe_label_map.get(cwe_type_labels[i], 0)\n",
        "            features = convert_examples_to_features(funcs[i], cwe_type_label, tokenizer, args.block_size)\n",
        "            self.examples.append(features)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': torch.tensor(self.examples[idx].input_ids),\n",
        "            'attention_mask': torch.tensor(self.examples[idx].attention_mask),\n",
        "            'labels': torch.tensor(self.examples[idx].cwe_type_label)\n",
        "        }"
      ],
      "metadata": {
        "id": "6qFg0f4XuTCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cwe_label_map = {\n",
        "    \"CWE-20\": 2,\n",
        "    \"CWE-119\": 1,\n",
        "    \"CWE-78\": 3,\n",
        "    \"CWE-122\": 4,\n",
        "    \"CWE-121\": 5,\n",
        "    \"CWE-415\": 6,\n",
        "    \"CWE-399\": 7,\n",
        "    \"CWE-190\": 8,\n",
        "    \"CWE-125\": 9,\n",
        "    \"CWE-416\": 10\n",
        "    # 여기에 더 많은 CWE ID와 인덱스 매핑을 추가할 수 있습니다.\n",
        "}"
      ],
      "metadata": {
        "id": "gMV2azhUpSGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋과 데이터 로더 생성\n",
        "train_dataset = TextDataset(tokenizer, args, cwe_label_map, file_type='train')\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uvoTMU8uYfy",
        "outputId": "5c0408cd-f2e0-4f7e-e692-b2427650a94a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-ecd94340a22e>:6: DtypeWarning: Columns (106) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path)\n",
            "  0%|          | 0/27982 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2645: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "100%|██████████| 27982/27982 [01:14<00:00, 376.71it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def compute_adjustment(tau, args, cwe_label_map):\n",
        "    \"\"\"클래스 빈도에 따라 로짓 조정 값을 계산합니다.\n",
        "\n",
        "    Args:\n",
        "        tau (float): 조정 계수, 클래스 빈도의 지수화에 사용됩니다.\n",
        "        args (Args class): 설정 정보를 담고 있는 클래스 인스턴스.\n",
        "        cwe_label_map (dict): 각 CWE ID에 대한 [index, one_hot, frequency] 정보를 담은 사전.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: 조정된 로짓 값들이 담긴 텐서.\n",
        "    \"\"\"\n",
        "    # 빈도 수집: 사전 순서대로 빈도를 배열에 저장\n",
        "    freq = [v[2] for k, v in sorted(cwe_label_map.items(), key=lambda item: item[1][0])]\n",
        "\n",
        "    # 레이블 빈도를 PyTorch 텐서로 변환하고 정규화\n",
        "    label_freq_tensor = torch.tensor(freq, dtype=torch.float32, device=args.device)\n",
        "    label_freq_tensor /= label_freq_tensor.sum()\n",
        "\n",
        "    # 로짓 조정 계산\n",
        "    adjustments = torch.log(torch.pow(label_freq_tensor, tau) + 1e-12)\n",
        "\n",
        "    return adjustments\n"
      ],
      "metadata": {
        "id": "8LLkkGJ8uZHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_adjustment(tau, args, cwe_label_map):\n",
        "    \"\"\"클래스 빈도에 따라 로짓 조정 값을 계산합니다.\n",
        "\n",
        "    Args:\n",
        "        tau (float): 조정 계수, 클래스 빈도의 지수화에 사용됩니다.\n",
        "        args (Args class): 설정 정보를 담고 있는 클래스 인스턴스.\n",
        "        cwe_label_map (dict): 각 CWE ID에 대한 [index, one_hot, frequency] 정보를 담은 사전.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: 조정된 로짓 값들이 담긴 텐서.\n",
        "    \"\"\"\n",
        "    # 빈도 수집: 사전 순서대로 빈도를 배열에 저장\n",
        "    freq = [v[2] for k, v in sorted(cwe_label_map.items(), key=lambda item: item[1][0])]\n",
        "\n",
        "    # 레이블 빈도를 PyTorch 텐서로 변환하고 정규화\n",
        "    label_freq_tensor = torch.tensor(freq, dtype=torch.float32, device=args.device)\n",
        "    label_freq_tensor /= label_freq_tensor.sum()\n",
        "\n",
        "    # 로짓 조정 계산\n",
        "    adjustments = torch.log(torch.pow(label_freq_tensor, tau) + 1e-12)\n",
        "\n",
        "    return adjustments"
      ],
      "metadata": {
        "id": "acpqOVO4DxGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def set_seed(args):\n",
        "    \"\"\"\n",
        "    모든 난수 생성기의 시드를 설정하여 실험의 재현성을 보장합니다.\n",
        "\n",
        "    Args:\n",
        "    - args (Args class): 시드와 GPU 사용 여부를 포함하는 설정 클래스 인스턴스.\n",
        "\n",
        "    이 함수는 Python의 내장 난수 생성기, NumPy, 그리고 PyTorch에 대해 동일한 시드를 설정합니다.\n",
        "    또한, 여러 GPU를 사용하는 경우 각 디바이스의 CUDA 난수 생성기에 대해서도 시드를 설정합니다.\n",
        "    \"\"\"\n",
        "    random.seed(args.seed)  # Python 내장 난수 생성기의 시드 설정\n",
        "    np.random.seed(args.seed)  # NumPy 난수 생성기의 시드 설정\n",
        "    torch.manual_seed(args.seed)  # PyTorch 난수 생성기의 시드 설정\n",
        "\n",
        "    # CUDA 난수 생성기의 시드 설정 (GPU 사용 시)\n",
        "    if args.n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "# 예시로 Args 클래스를 정의하고 seed와 n_gpu를 설정합니다.\n",
        "class Args:\n",
        "    seed = 42\n",
        "    n_gpu = 1  # 이 값을 Colab에서 사용할 GPU 수에 맞춰 설정하세요.\n",
        "\n",
        "args = Args()\n",
        "set_seed(args)  # 시드 설정 함수 호출\n"
      ],
      "metadata": {
        "id": "RM9vMADuEG-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train(args, train_dataset, model, tokenizer, eval_dataset, cwe_label_map):\n",
        "    \"\"\" 모델을 훈련합니다. \"\"\"\n",
        "    # 데이터 로더 구성\n",
        "    train_sampler = RandomSampler(train_dataset)\n",
        "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size, num_workers=0)\n",
        "\n",
        "    # 로짓 조정 사용 여부 확인\n",
        "    if args.use_logit_adjustment:\n",
        "        logit_adjustment = compute_adjustment(tau=args.tau, args=args, cwe_label_map=cwe_label_map)\n",
        "    else:\n",
        "        logit_adjustment = None\n",
        "\n",
        "    # 최적화 도구 및 스케줄러 설정\n",
        "    optimizer = AdamW(model.parameters(), lr=args.learning_rate, eps=args.adam_epsilon)\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=args.max_steps)\n",
        "\n",
        "    model.to(args.device)\n",
        "    model.train()\n",
        "\n",
        "    # 훈련 루프\n",
        "    for epoch in range(args.epochs):\n",
        "        total_loss = 0\n",
        "        for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\"):\n",
        "            batch = {k: v.to(args.device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            loss = outputs.loss\n",
        "\n",
        "            if args.n_gpu > 1:\n",
        "                loss = loss.mean()  # multi-gpu 지원\n",
        "            if args.gradient_accumulation_steps > 1:\n",
        "                loss = loss / args.gradient_accumulation_steps\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "        # 에폭 종료 후 평가\n",
        "        if eval_dataset is not None:\n",
        "            eval_loss = evaluate(args, model, tokenizer, eval_dataset)\n",
        "            print(f\"Epoch {epoch + 1} Evaluation Loss: {eval_loss:.4f}\")\n",
        "\n",
        "        # 로스 감소 시 체크포인트 저장\n",
        "        if eval_loss < best_loss:\n",
        "            best_loss = eval_loss\n",
        "            save_checkpoint(model, args.output_dir, 'best_model.pt')\n",
        "\n",
        "def save_checkpoint(model, save_path, filename):\n",
        "    \"\"\" 모델 상태를 파일로 저장합니다. \"\"\"\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "    torch.save(model.state_dict(), os.path.join(save_path, filename))\n"
      ],
      "metadata": {
        "id": "Cit80wEBD6mR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def evaluate(args, model, tokenizer, eval_dataset, eval_when_training=False):\n",
        "    # DataLoader 생성\n",
        "    eval_sampler = SequentialSampler(eval_dataset)\n",
        "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size, num_workers=0)\n",
        "\n",
        "    # Multi-GPU 설정\n",
        "    if args.n_gpu > 1 and not eval_when_training:\n",
        "        original_model = model\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # 모델 평가 모드 설정\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_examples = 0\n",
        "\n",
        "    # 평가 진행\n",
        "    logger.info(\"***** Running evaluation *****\")\n",
        "    logger.info(\"Num examples = %d\", len(eval_dataset))\n",
        "    logger.info(\"Batch size = %d\", args.eval_batch_size)\n",
        "    for batch in eval_dataloader:\n",
        "        batch = {k: v.to(args.device) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "            total_examples += batch['input_ids'].size(0)\n",
        "\n",
        "    # 평균 손실 계산\n",
        "    avg_loss = total_loss / total_examples\n",
        "\n",
        "    # Multi-GPU 상태를 원래대로 복원\n",
        "    if args.n_gpu > 1 and not eval_when_training:\n",
        "        model = original_model\n",
        "\n",
        "    # 결과 로깅\n",
        "    logger.info(\"***** Eval results *****\")\n",
        "    logger.info(\"Total loss = %.4f\", avg_loss)\n",
        "\n",
        "    # 결과 반환\n",
        "    result = {\n",
        "        \"eval_total_loss\": avg_loss\n",
        "    }\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "wiW2h08tEb8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def test(args, model, tokenizer, test_dataset, best_threshold=0.5):\n",
        "    # DataLoader 구성\n",
        "    test_sampler = SequentialSampler(test_dataset)\n",
        "    test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=args.eval_batch_size, num_workers=0)\n",
        "\n",
        "    # 다중 GPU 설정\n",
        "    if args.n_gpu > 1:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # 모델 평가 모드 설정\n",
        "    model.eval()\n",
        "    logger.info(\"***** Running Test *****\")\n",
        "    logger.info(\"Num examples = %d\", len(test_dataset))\n",
        "    logger.info(\"Batch size = %d\", args.eval_batch_size)\n",
        "\n",
        "    # 예측 및 실제 레이블 저장용 리스트\n",
        "    cwe_type_preds = []\n",
        "    cwe_type_trues = []\n",
        "\n",
        "    # 테스트 데이터에 대한 평가\n",
        "    for batch in test_dataloader:\n",
        "        batch = {k: v.to(args.device) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "            logits = outputs.logits\n",
        "            predictions = torch.argmax(logits, dim=-1)\n",
        "            cwe_type_preds.extend(predictions.cpu().numpy())\n",
        "            cwe_type_trues.extend(batch['labels'].cpu().numpy())\n",
        "\n",
        "    # 정확도 계산\n",
        "    cwe_type_acc = accuracy_score(cwe_type_trues, cwe_type_preds)\n",
        "    result_cwe = {\"CWE Type Accuracy\": cwe_type_acc}\n",
        "\n",
        "    # 결과 로깅\n",
        "    logger.info(\"***** CWE Type Classification Test Results *****\")\n",
        "    for key, value in result_cwe.items():\n",
        "        logger.info(f\"{key} = {value:.4f}\")\n",
        "\n",
        "    return result_cwe\n"
      ],
      "metadata": {
        "id": "SxigSWdzE_gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "    # Argument parsing\n",
        "    parser = argparse.ArgumentParser(description=\"Train and evaluate the BERT model on CWE identification task\")\n",
        "    # Required parameters\n",
        "    parser.add_argument(\"--use_logit_adjustment\", action='store_true', help=\"Whether to use logit adjustment\")\n",
        "    # 여기에 다른 arguments 정의\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Setup CUDA, GPU\n",
        "    args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    args.n_gpu = torch.cuda.device_count()\n",
        "    logging.basicConfig(level=logging.INFO)\n",
        "    logger = logging.getLogger(__name__)\n",
        "    logger.info(f\"Device: {args.device}, Number of GPUs: {args.n_gpu}\")\n",
        "\n",
        "    # Random seed 설정\n",
        "    set_seed(args)\n",
        "\n",
        "    # Load tokenizers and models\n",
        "    tokenizer = RobertaTokenizer.from_pretrained(args.tokenizer_name)\n",
        "    model = BERT(roberta=RobertaModel.from_pretrained(args.model_name_or_path), tokenizer=tokenizer, num_cwe_types=10, args=args)\n",
        "    model.to(args.device)\n",
        "\n",
        "    # 데이터셋 로딩\n",
        "    train_dataset = TextDataset(args.train_data_file, tokenizer)\n",
        "    eval_dataset = TextDataset(args.eval_data_file, tokenizer)\n",
        "\n",
        "    # 훈련과 평가 실행\n",
        "    if args.do_train:\n",
        "        logger.info(\"Starting training...\")\n",
        "        train(args, model, train_dataset, eval_dataset)\n",
        "\n",
        "    if args.do_eval:\n",
        "        logger.info(\"Starting evaluation...\")\n",
        "        evaluate(args, model, eval_dataset)\n",
        "\n",
        "    if args.do_test:\n",
        "        logger.info(\"Starting testing...\")\n",
        "        test(args, model, tokenizer, test_dataset)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "UCCkuq-BFReg",
        "outputId": "962b5551-f662-45bc-fc0b-3f1e0e6b1a90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: colab_kernel_launcher.py [-h]\n",
            "colab_kernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-b26f8e3a-14b2-4dd9-8f34-1721d5d576f9.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "2",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}