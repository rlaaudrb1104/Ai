{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOSKLXg7e21MG+EoW9WQ/vU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "466d9f99cba643c9bda8231de56d63e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f081b0c3759a4e25b8c5e44c7a79ca51",
              "IPY_MODEL_3e1a7f9e04e647299b68fd385eb92798",
              "IPY_MODEL_1497b12be10a4cffaff6f5c16c8683a9"
            ],
            "layout": "IPY_MODEL_6098ca94afc04956a28d552ea4928d11"
          }
        },
        "f081b0c3759a4e25b8c5e44c7a79ca51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0b64c0505d64507b96e0aad324d4bc0",
            "placeholder": "​",
            "style": "IPY_MODEL_9bd76d5557f74048980f6cf174fcd23a",
            "value": "Generating train split: "
          }
        },
        "3e1a7f9e04e647299b68fd385eb92798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25db09a8e3744fc2be8c2342e987eaec",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c57d194137ba4ec78d299f19fd448832",
            "value": 1
          }
        },
        "1497b12be10a4cffaff6f5c16c8683a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_416e6c3bbaea45718c7aa3507fb87fa1",
            "placeholder": "​",
            "style": "IPY_MODEL_d97865f65a1f44c3be5375e021466cff",
            "value": " 9860/0 [00:00&lt;00:00, 78690.74 examples/s]"
          }
        },
        "6098ca94afc04956a28d552ea4928d11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0b64c0505d64507b96e0aad324d4bc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bd76d5557f74048980f6cf174fcd23a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25db09a8e3744fc2be8c2342e987eaec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c57d194137ba4ec78d299f19fd448832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "416e6c3bbaea45718c7aa3507fb87fa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d97865f65a1f44c3be5375e021466cff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22df6b48df2c43d6ac245a464c6f653e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f21576b43494847af6b895f7fd49e79",
              "IPY_MODEL_8c6ec23e3dbd498098ebcc342af9952a",
              "IPY_MODEL_39bedd04140e4999a5d5493ba680200c"
            ],
            "layout": "IPY_MODEL_21789891c56e415697f7a1b86c3a7769"
          }
        },
        "4f21576b43494847af6b895f7fd49e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d8f801eba32475cb5f208f3abcf9c31",
            "placeholder": "​",
            "style": "IPY_MODEL_8b49ee50a0964163b05ca5f2710ac588",
            "value": "Map: 100%"
          }
        },
        "8c6ec23e3dbd498098ebcc342af9952a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aceaa7a5488046d283b76b9ce46f1b1b",
            "max": 18315,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1187cc79901e41bcb2f0768c328e3136",
            "value": 18315
          }
        },
        "39bedd04140e4999a5d5493ba680200c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0689a43e9d94c66be682823fa05288a",
            "placeholder": "​",
            "style": "IPY_MODEL_57e5a025c6964d038dca7db392856d94",
            "value": " 18315/18315 [00:06&lt;00:00, 2789.59 examples/s]"
          }
        },
        "21789891c56e415697f7a1b86c3a7769": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d8f801eba32475cb5f208f3abcf9c31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b49ee50a0964163b05ca5f2710ac588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aceaa7a5488046d283b76b9ce46f1b1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1187cc79901e41bcb2f0768c328e3136": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0689a43e9d94c66be682823fa05288a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57e5a025c6964d038dca7db392856d94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rlaaudrb1104/Ai/blob/PJH/New_Graphcodebert_%ED%95%98%EC%9D%B4%ED%8D%BC%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0%EC%9E%90%EB%8F%99%ED%99%94.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-71ibgKSW4D-",
        "outputId": "6f354f87-8b71-4986-8184-241b350d53a5"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu5QIf9zW1RU",
        "outputId": "6ac13c5f-7a3f-45aa-aeae-3fe75ded7ae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.30.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.10/dist-packages (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (2.0.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.4)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (24.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.10/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.13.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate -U\n",
        "!pip install transformers[torch] -U\n",
        "!pip install shap\n",
        "!pip install datasets\n",
        "!pip install optuna\n",
        "!pip install imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import optuna\n",
        "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification, AutoTokenizer\n",
        "from datasets import load_dataset, Dataset\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import re\n",
        "from transformers import DataCollatorWithPadding\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "gut2g6ynW4A7"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드 및 전처리\n",
        "df = pd.read_csv('/content/drive/MyDrive/data/MSR+julite+Div_final_train(2500cut_plus_alpha).csv')"
      ],
      "metadata": {
        "id": "kB3xJDSyW3-q"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = ['CWE ID', 'vul', 'lang']\n",
        "df = df.drop(columns=columns_to_drop)\n",
        "\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7WxhtcDZgQ-",
        "outputId": "a219ecb1-a09b-4b2d-ea54-7376ee0512f3"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['code', 'labels'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sort_values(by=['labels'])\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "j2xzdtsdW35t"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 함수 정의\n",
        "def preprocess(df, file_name):\n",
        "    # 멀티 라인 주석 제거\n",
        "    df['code'] = df['code'].replace(re.compile(r'/\\*.*?\\*/', re.DOTALL), \"\", regex=True)\n",
        "    # 싱글 라인 주석 제거\n",
        "    df['code'] = df['code'].replace(re.compile(r'//.*?\\n'), \"\", regex=True)\n",
        "    # angle brackets를 사용하는 include 제거\n",
        "    df['code'] = df['code'].replace(re.compile(r'#include <.*?>\\n'), \"\", regex=True)\n",
        "    df['code'] = df['code'].replace(re.compile(r'#include \".*?\"\\n'), \"\", regex=True)\n",
        "    # 매크로 정의 제거\n",
        "    df['code'] = df['code'].replace(re.compile(r'#define .*?\\n'), \"\", regex=True)\n",
        "    # 전처리 지시문 제거\n",
        "    df['code'] = df['code'].replace(re.compile(r'#undef\\s+\\w+'), \"\", regex=True)\n",
        "    df['code'] = df['code'].replace(re.compile(r'#if\\s+\\w+'), \"\", regex=True)\n",
        "    df['code'] = df['code'].replace(re.compile(r'#else\\s+\\w+'), \"\", regex=True)\n",
        "    df['code'] = df['code'].replace(re.compile(r'#elif\\s+\\w+'), \"\", regex=True)\n",
        "    df['code'] = df['code'].replace(re.compile(r'#endif'), \"\", regex=True)\n",
        "    df['code'] = df['code'].replace(re.compile(r'#indef'),\"\", regex=True)\n",
        "    # 탭과 여러 공백을 하나의 공백으로\n",
        "    df['code'] = df['code'].replace(re.compile(r'[\\t ]+'), \" \", regex=True)\n",
        "    # 여러 줄바꿈을 하나로\n",
        "    df['code'] = df['code'].replace(re.compile(r'\\n\\s*\\n'), \"\\n\", regex=True)\n",
        "    df['code'] = df['code'].replace(re.compile(r'\\n'), \" \", regex=True)\n",
        "    df['code'] = df['code'].replace(re.compile(r'return\\s*.*?;'), \"\", regex=True)\n",
        "    df['code'] = df['code'].replace(re.compile(r'return;'), \"\", regex=True)\n",
        "    # void func로 변경\n",
        "    df['code'] = df['code'].replace(re.compile(r'\\b([a-zA-Z_]\\w*)\\s+([a-zA-Z_]\\w*)\\s*\\(.*?\\)\\s*{'), r\"void func() {\", regex=True)\n",
        "    # 중복된 code 내용 제거\n",
        "    df = df.drop_duplicates(subset=['code'])\n",
        "\n",
        "    # 데이터프레임을 CSV 파일로 저장\n",
        "    df.to_csv(file_name, index=False)\n",
        "    return df  # 수정된 데이터프레임 반환"
      ],
      "metadata": {
        "id": "Kojti6cVW32u"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋을 Pandas DataFrame으로 변환\n",
        "df = preprocess(df, \"preprocess.csv\")"
      ],
      "metadata": {
        "id": "l6HgTmyIW3z8"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 오버샘플링 적용\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_res, y_res = ros.fit_resample(df.drop(columns=['labels']), df['labels'])"
      ],
      "metadata": {
        "id": "A7bFzZs5W3xR"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 오버샘플링 후 클래스 분포 확인\n",
        "print(f\"Resampled dataset shape: {Counter(y_res)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iahgR31OZsNK",
        "outputId": "23a7a9ad-5ed3-4ec2-c558-dd574d15401a"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resampled dataset shape: Counter({0: 2035, 1: 2035, 2: 2035, 3: 2035, 4: 2035, 5: 2035, 6: 2035, 7: 2035, 8: 2035})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 오버샘플링된 데이터를 다시 Dataset 객체로 변환\n",
        "resampled_df = pd.concat([X_res, y_res], axis=1)\n",
        "resampled_dataset = Dataset.from_pandas(resampled_df)"
      ],
      "metadata": {
        "id": "ji4niStEZtej"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 토큰화 함수 정의\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/graphcodebert-base\")\n",
        "MAX_LEN = 512\n",
        "\n",
        "def tokenized(examples):\n",
        "    return tokenizer(examples['code'], pad_to_max_length=True, max_length=MAX_LEN, truncation=True, return_token_type_ids=True)"
      ],
      "metadata": {
        "id": "YkqjH0svZwmG"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 로드 및 전처리\n",
        "dataset = load_dataset(\"csv\", data_files=\"preprocess.csv\")['train']\n",
        "encoded_dataset = resampled_dataset.map(tokenized, remove_columns=['code'], batched=True)\n",
        "\n",
        "encoded_dataset = encoded_dataset.train_test_split(0.3, seed=11)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "466d9f99cba643c9bda8231de56d63e6",
            "f081b0c3759a4e25b8c5e44c7a79ca51",
            "3e1a7f9e04e647299b68fd385eb92798",
            "1497b12be10a4cffaff6f5c16c8683a9",
            "6098ca94afc04956a28d552ea4928d11",
            "f0b64c0505d64507b96e0aad324d4bc0",
            "9bd76d5557f74048980f6cf174fcd23a",
            "25db09a8e3744fc2be8c2342e987eaec",
            "c57d194137ba4ec78d299f19fd448832",
            "416e6c3bbaea45718c7aa3507fb87fa1",
            "d97865f65a1f44c3be5375e021466cff",
            "22df6b48df2c43d6ac245a464c6f653e",
            "4f21576b43494847af6b895f7fd49e79",
            "8c6ec23e3dbd498098ebcc342af9952a",
            "39bedd04140e4999a5d5493ba680200c",
            "21789891c56e415697f7a1b86c3a7769",
            "9d8f801eba32475cb5f208f3abcf9c31",
            "8b49ee50a0964163b05ca5f2710ac588",
            "aceaa7a5488046d283b76b9ce46f1b1b",
            "1187cc79901e41bcb2f0768c328e3136",
            "a0689a43e9d94c66be682823fa05288a",
            "57e5a025c6964d038dca7db392856d94"
          ]
        },
        "id": "2_bP3cEuZtVS",
        "outputId": "b7bd78a2-ce8c-4990-a87d-1322220a33ef"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "466d9f99cba643c9bda8231de56d63e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/18315 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22df6b48df2c43d6ac245a464c6f653e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2699: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 레이블 값 출력 확인\n",
        "print(encoded_dataset['train']['labels'])\n",
        "print(encoded_dataset['test']['labels'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYmryE3mZ1SZ",
        "outputId": "7da9275e-2e06-4b8c-df6b-5f104770b3e7"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 7, 7, 5, 5, 5, 7, 4, 3, 6, 8, 7, 7, 6, 1, 0, 0, 5, 1, 1, 3, 7, 4, 2, 6, 8, 4, 8, 2, 0, 8, 6, 3, 3, 5, 1, 4, 5, 3, 1, 7, 2, 7, 0, 1, 4, 6, 8, 5, 4, 8, 6, 1, 4, 7, 3, 7, 7, 5, 1, 1, 5, 3, 2, 1, 1, 2, 3, 1, 7, 6, 8, 3, 2, 4, 8, 1, 6, 0, 5, 1, 8, 2, 5, 0, 2, 4, 3, 1, 8, 8, 1, 2, 6, 0, 8, 8, 2, 1, 6, 0, 4, 3, 5, 7, 2, 2, 2, 2, 3, 1, 5, 4, 0, 1, 1, 3, 5, 7, 5, 3, 1, 5, 5, 1, 5, 7, 0, 4, 8, 0, 1, 8, 4, 6, 7, 0, 2, 3, 5, 1, 7, 8, 2, 6, 5, 7, 1, 5, 4, 8, 6, 0, 7, 2, 7, 1, 7, 3, 6, 4, 1, 6, 7, 0, 7, 0, 7, 5, 5, 6, 4, 2, 8, 3, 0, 3, 5, 7, 5, 0, 6, 4, 4, 6, 6, 6, 2, 5, 7, 0, 4, 1, 4, 2, 5, 3, 8, 1, 0, 1, 2, 4, 0, 6, 5, 8, 7, 6, 8, 1, 4, 7, 5, 8, 0, 3, 0, 8, 2, 7, 2, 6, 7, 0, 6, 5, 8, 7, 8, 7, 5, 7, 2, 1, 6, 7, 2, 5, 5, 2, 0, 0, 0, 2, 1, 2, 1, 6, 5, 7, 2, 5, 7, 3, 2, 4, 3, 7, 8, 7, 6, 6, 6, 6, 6, 8, 0, 0, 4, 5, 7, 5, 1, 5, 7, 0, 3, 8, 0, 2, 6, 1, 8, 3, 2, 1, 8, 0, 7, 7, 4, 0, 5, 4, 4, 7, 7, 8, 3, 3, 8, 0, 3, 7, 4, 6, 5, 3, 0, 0, 5, 0, 0, 7, 3, 1, 0, 7, 8, 5, 2, 7, 6, 2, 0, 4, 0, 7, 4, 6, 7, 6, 0, 5, 8, 2, 3, 4, 5, 1, 0, 3, 0, 1, 1, 4, 2, 2, 7, 8, 0, 7, 0, 8, 6, 0, 2, 5, 4, 3, 7, 7, 5, 2, 7, 2, 4, 2, 4, 8, 3, 5, 0, 2, 7, 0, 3, 1, 7, 3, 3, 2, 0, 8, 1, 1, 1, 4, 3, 4, 5, 4, 6, 0, 3, 2, 6, 2, 8, 4, 0, 1, 8, 6, 6, 8, 8, 4, 7, 5, 4, 4, 7, 6, 4, 2, 6, 5, 0, 6, 2, 7, 8, 1, 0, 3, 5, 5, 6, 4, 5, 2, 0, 1, 2, 6, 4, 3, 3, 7, 3, 4, 1, 6, 2, 0, 5, 2, 2, 3, 6, 1, 4, 7, 3, 2, 4, 0, 1, 2, 8, 1, 2, 7, 5, 7, 5, 0, 3, 2, 3, 3, 8, 4, 2, 7, 1, 6, 2, 1, 4, 1, 3, 3, 7, 6, 6, 4, 3, 6, 5, 4, 8, 8, 0, 6, 6, 8, 0, 2, 4, 4, 7, 4, 1, 4, 7, 0, 8, 2, 2, 5, 2, 3, 3, 4, 2, 7, 0, 1, 3, 5, 7, 8, 1, 4, 0, 5, 1, 5, 1, 8, 6, 5, 4, 5, 8, 2, 6, 2, 7, 7, 5, 6, 7, 1, 0, 0, 0, 0, 5, 1, 0, 7, 0, 5, 6, 2, 5, 7, 6, 4, 3, 4, 1, 6, 0, 3, 1, 7, 0, 1, 3, 2, 2, 2, 0, 4, 2, 8, 5, 5, 8, 0, 7, 0, 7, 3, 2, 5, 5, 3, 2, 2, 0, 7, 4, 6, 3, 0, 7, 7, 1, 2, 6, 6, 0, 8, 5, 0, 4, 8, 3, 1, 1, 2, 6, 4, 0, 8, 5, 6, 0, 4, 1, 3, 1, 7, 8, 6, 6, 5, 8, 7, 6, 0, 6, 5, 0, 4, 8, 8, 5, 6, 2, 0, 8, 3, 1, 4, 2, 0, 2, 6, 3, 1, 3, 6, 8, 4, 5, 0, 8, 1, 0, 4, 8, 6, 3, 0, 6, 4, 7, 0, 6, 6, 7, 6, 1, 5, 5, 3, 2, 8, 7, 3, 5, 1, 4, 2, 0, 8, 8, 6, 2, 5, 4, 8, 1, 0, 6, 8, 2, 8, 4, 2, 3, 7, 1, 4, 6, 5, 8, 3, 3, 5, 4, 3, 6, 2, 5, 2, 3, 5, 6, 8, 8, 2, 1, 4, 2, 5, 6, 3, 2, 1, 6, 7, 2, 3, 4, 4, 8, 0, 5, 4, 4, 3, 5, 7, 0, 5, 4, 0, 6, 6, 7, 2, 8, 0, 4, 4, 8, 2, 3, 5, 4, 0, 4, 5, 5, 2, 2, 2, 4, 0, 5, 7, 5, 0, 0, 8, 7, 2, 8, 1, 4, 3, 4, 1, 1, 8, 7, 1, 7, 4, 4, 7, 0, 4, 5, 4, 6, 0, 5, 7, 6, 0, 1, 5, 3, 4, 2, 0, 7, 0, 2, 0, 7, 7, 1, 5, 4, 4, 3, 3, 3, 7, 7, 4, 0, 8, 7, 3, 6, 4, 2, 3, 5, 0, 8, 3, 4, 7, 2, 7, 1, 5, 6, 6, 2, 7, 1, 6, 4, 2, 6, 7, 1, 2, 5, 3, 8, 0, 0, 0, 5, 4, 6, 0, 6, 5, 3, 6, 5, 6, 1, 5, 6, 7, 5, 8, 4, 1, 2, 3, 3, 4, 1, 7, 2, 8, 0, 3, 2, 8, 0, 5, 5, 8, 5, 6, 7, 3, 7, 0, 1, 0, 6, 6, 0, 1, 3, 2, 1, 8, 8, 4, 0, 6, 2, 6, 1, 7, 4, 3, 8, 2, 2, 7, 5, 0, 4, 6, 0, 1, 2, 2, 1, 6, 5, 7, 3, 6, 0, 0, 1, 0, 7, 7, 0, 3, 3, 0, 7, 1, 0, 2, 4, 8, 2, 3, 2, 2, 6, 5, 2, 8, 8, 1, 6, 5, 8, 8, 7, 3, 7, 2, 4, 7, 4, 3, 7, 6, 5, 7, 3, 8, 0, 4, 4, 3, 4, 4, 3, 6, 1, 7, 6, 7, 2, 6, 2, 6, 3, 8, 7, 1, 4, 5, 0, 8, 5, 5, 7, 0, 4, 7, 4, 7, 1, 5, 0, 6, 1, 7, 5, 2, 5, 3, 4, 6, 4, 1, 7, 8, 6, 0, 0, 6, 4, 8, 5, 4, 2, 0, 7, 6, 5, 3, 0, 5, 7, 7, 2, 7, 8, 5, 0, 4, 3, 8, 8, 4, 7, 7, 8, 7, 3, 7, 2, 3, 3, 0, 0, 3, 3, 6, 6, 2, 1, 7, 4, 3, 8, 7, 8, 0, 4, 8, 5, 5, 8, 3, 4, 3, 8, 5, 2, 4, 6, 6, 0, 2, 4, 0, 6, 8, 3, 4, 6, 3, 3, 8, 5, 2, 4, 0, 8, 1, 7, 5, 5, 4, 8, 3, 5, 0, 6, 0, 1, 6, 5, 0, 5, 8, 4, 7, 0, 4, 3, 4, 3, 8, 1, 5, 1, 1, 1, 6, 2, 4, 2, 4, 1, 0, 7, 4, 0, 6, 7, 0, 0, 2, 1, 7, 6, 3, 8, 2, 7, 7, 5, 2, 5, 0, 4, 1, 8, 0, 7, 2, 6, 2, 0, 5, 5, 4, 1, 3, 2, 0, 2, 3, 7, 8, 3, 6, 5, 4, 3, 3, 2, 8, 2, 7, 4, 3, 5, 1, 5, 5, 6, 7, 2, 3, 0, 2, 5, 2, 5, 1, 3, 2, 7, 2, 4, 6, 2, 2, 6, 2, 2, 0, 0, 6, 5, 8, 4, 0, 6, 5, 6, 6, 4, 5, 1, 7, 3, 4, 3, 6, 6, 4, 2, 5, 4, 4, 7, 7, 0, 1, 5, 3, 6, 5, 0, 7, 7, 7, 4, 1, 2, 1, 5, 4, 7, 1, 6, 4, 7, 3, 3, 5, 8, 1, 5, 6, 4, 2, 3, 2, 4, 4, 5, 2, 5, 0, 5, 0, 1, 6, 4, 5, 8, 6, 4, 3, 6, 4, 3, 2, 0, 6, 8, 2, 0, 2, 8, 4, 5, 8, 0, 5, 7, 6, 3, 5, 1, 7, 5, 7, 6, 2, 2, 2, 6, 8, 6, 3, 4, 5, 3, 2, 0, 8, 4, 1, 6, 5, 0, 2, 4, 2, 8, 5, 6, 1, 8, 5, 3, 4, 5, 0, 7, 2, 3, 7, 8, 0, 7, 2, 6, 6, 8, 5, 6, 3, 0, 3, 7, 1, 8, 0, 7, 5, 1, 6, 6, 7, 0, 5, 4, 5, 4, 4, 5, 5, 0, 1, 0, 6, 3, 4, 7, 2, 5, 2, 2, 6, 2, 3, 8, 3, 8, 4, 8, 4, 4, 3, 2, 2, 3, 4, 6, 7, 5, 5, 7, 4, 4, 4, 0, 4, 8, 2, 6, 5, 1, 3, 3, 1, 3, 7, 7, 6, 3, 1, 5, 3, 5, 3, 4, 5, 4, 0, 1, 2, 5, 2, 1, 8, 6, 2, 2, 6, 6, 4, 3, 1, 6, 5, 6, 8, 4, 5, 1, 1, 0, 2, 4, 2, 4, 6, 1, 8, 8, 7, 4, 4, 1, 7, 8, 2, 8, 6, 8, 4, 6, 3, 4, 6, 3, 5, 8, 0, 5, 7, 4, 1, 0, 7, 8, 2, 6, 1, 2, 0, 3, 3, 2, 1, 1, 6, 6, 2, 4, 7, 0, 7, 1, 4, 5, 2, 6, 0, 7, 4, 3, 6, 1, 0, 7, 8, 5, 6, 3, 6, 5, 7, 2, 8, 4, 2, 8, 2, 1, 2, 4, 6, 3, 0, 1, 4, 4, 8, 6, 3, 3, 2, 0, 8, 6, 7, 0, 0, 0, 3, 4, 5, 6, 8, 0, 2, 8, 5, 7, 8, 8, 5, 5, 8, 5, 1, 3, 7, 6, 8, 0, 8, 8, 0, 8, 1, 0, 5, 4, 8, 5, 2, 1, 8, 5, 2, 1, 1, 1, 0, 8, 4, 1, 6, 0, 1, 4, 4, 1, 5, 4, 5, 2, 1, 4, 4, 5, 7, 5, 6, 3, 4, 4, 1, 0, 6, 6, 1, 8, 2, 8, 8, 3, 6, 5, 4, 7, 2, 7, 8, 5, 4, 1, 4, 7, 6, 2, 5, 7, 2, 5, 2, 6, 2, 2, 0, 8, 8, 6, 0, 3, 4, 8, 0, 3, 0, 5, 2, 2, 1, 2, 2, 0, 0, 8, 0, 6, 2, 5, 4, 8, 8, 3, 8, 6, 7, 5, 4, 6, 6, 7, 7, 3, 3, 1, 8, 6, 4, 8, 3, 8, 1, 7, 2, 3, 1, 0, 7, 6, 5, 0, 1, 5, 4, 3, 8, 8, 5, 2, 8, 7, 2, 3, 6, 8, 0, 5, 4, 7, 1, 7, 7, 1, 1, 7, 8, 6, 8, 8, 1, 8, 4, 8, 4, 3, 4, 3, 0, 6, 8, 0, 3, 5, 4, 4, 1, 4, 7, 8, 3, 2, 1, 4, 5, 2, 6, 0, 0, 1, 0, 1, 5, 4, 5, 5, 3, 1, 2, 6, 2, 2, 5, 8, 3, 6, 0, 7, 7, 0, 3, 5, 2, 4, 4, 8, 0, 2, 6, 1, 4, 2, 1, 6, 0, 8, 5, 3, 2, 4, 6, 5, 8, 0, 2, 0, 1, 8, 7, 1, 0, 3, 6, 6, 8, 8, 7, 1, 2, 2, 5, 2, 8, 8, 3, 2, 1, 1, 4, 6, 3, 8, 8, 8, 6, 1, 8, 4, 1, 6, 8, 4, 8, 8, 4, 7, 8, 5, 2, 3, 2, 1, 3, 1, 1, 1, 8, 1, 2, 5, 4, 6, 2, 8, 1, 4, 6, 1, 1, 1, 3, 8, 5, 7, 6, 4, 2, 0, 2, 1, 6, 8, 5, 2, 2, 0, 6, 6, 6, 0, 5, 2, 5, 3, 3, 8, 5, 7, 2, 0, 7, 7, 2, 8, 8, 6, 1, 2, 1, 7, 1, 0, 0, 2, 1, 4, 5, 8, 1, 2, 4, 3, 2, 0, 5, 3, 0, 1, 5, 3, 4, 3, 5, 1, 5, 2, 0, 7, 1, 7, 2, 6, 4, 6, 1, 6, 4, 2, 8, 1, 7, 3, 1, 3, 1, 5, 1, 2, 1, 0, 7, 8, 2, 5, 2, 2, 7, 4, 8, 3, 1, 7, 0, 2, 6, 4, 1, 8, 2, 5, 2, 5, 3, 1, 4, 2, 0, 8, 7, 6, 6, 5, 2, 4, 0, 0, 4, 3, 4, 2, 3, 7, 3, 1, 5, 1, 3, 3, 1, 6, 6, 8, 2, 1, 6, 6, 8, 2, 6, 8, 6, 6, 8, 0, 4, 6, 8, 8, 5, 1, 6, 0, 1, 3, 4, 1, 3, 6, 3, 7, 1, 7, 7, 6, 4, 3, 6, 3, 7, 3, 3, 8, 4, 3, 3, 2, 7, 7, 1, 6, 2, 6, 8, 5, 2, 4, 6, 2, 2, 8, 3, 7, 3, 8, 2, 5, 5, 8, 8, 0, 2, 8, 1, 0, 1, 2, 2, 4, 3, 7, 1, 0, 1, 2, 4, 8, 8, 4, 7, 4, 4, 6, 6, 5, 0, 3, 5, 8, 1, 2, 5, 2, 1, 0, 4, 7, 1, 5, 2, 4, 0, 6, 8, 6, 0, 2, 5, 0, 5, 4, 0, 7, 5, 4, 1, 2, 3, 2, 4, 6, 1, 5, 4, 4, 8, 1, 5, 0, 2, 5, 4, 4, 4, 5, 1, 2, 1, 1, 6, 7, 8, 0, 8, 0, 4, 2, 0, 0, 2, 5, 4, 7, 2, 0, 8, 1, 4, 2, 5, 8, 0, 6, 6, 7, 0, 3, 6, 0, 3, 1, 2, 7, 1, 8, 8, 4, 3, 1, 3, 6, 8, 7, 5, 0, 2, 4, 6, 2, 1, 1, 2, 3, 6, 7, 4, 2, 7, 5, 7, 8, 1, 2, 5, 7, 5, 7, 6, 2, 8, 2, 6, 4, 8, 5, 2, 5, 3, 6, 2, 5, 4, 7, 4, 2, 8, 4, 1, 3, 2, 3, 2, 2, 3, 7, 3, 6, 5, 0, 7, 6, 5, 3, 8, 2, 5, 8, 0, 2, 3, 6, 4, 1, 5, 1, 3, 7, 7, 6, 8, 5, 2, 5, 3, 0, 1, 1, 6, 3, 8, 1, 6, 6, 5, 6, 0, 5, 3, 1, 5, 4, 0, 8, 4, 2, 4, 5, 1, 1, 4, 0, 7, 8, 3, 1, 1, 4, 7, 3, 8, 2, 0, 7, 7, 1, 8, 7, 7, 2, 6, 1, 5, 2, 0, 7, 7, 7, 2, 3, 0, 1, 7, 5, 8, 5, 3, 4, 7, 4, 4, 2, 8, 5, 4, 4, 1, 1, 0, 1, 2, 7, 8, 6, 1, 2, 1, 5, 7, 4, 2, 1, 2, 4, 7, 4, 6, 5, 0, 6, 1, 6, 1, 6, 2, 0, 3, 7, 1, 4, 4, 7, 8, 8, 7, 6, 3, 3, 0, 7, 7, 7, 5, 4, 2, 7, 5, 0, 8, 1, 0, 1, 6, 3, 3, 0, 4, 6, 0, 6, 5, 7, 0, 5, 8, 2, 2, 1, 7, 0, 0, 0, 3, 8, 2, 6, 3, 6, 3, 4, 0, 5, 0, 7, 8, 1, 7, 7, 0, 4, 7, 8, 0, 6, 7, 0, 5, 4, 7, 0, 8, 3, 1, 0, 1, 6, 3, 2, 1, 5, 4, 3, 8, 0, 8, 1, 4, 2, 1, 5, 4, 3, 6, 1, 7, 2, 8, 6, 0, 4, 5, 1, 3, 6, 1, 6, 5, 3, 5, 7, 5, 7, 5, 7, 7, 0, 0, 3, 5, 6, 8, 8, 5, 3, 7, 6, 2, 0, 8, 7, 0, 5, 7, 6, 0, 7, 0, 0, 2, 2, 7, 6, 5, 8, 2, 7, 4, 2, 5, 2, 6, 2, 5, 5, 7, 2, 1, 6, 8, 8, 8, 2, 8, 3, 1, 7, 2, 4, 3, 8, 2, 2, 0, 2, 5, 3, 3, 8, 6, 0, 8, 8, 6, 5, 2, 0, 3, 3, 2, 2, 8, 7, 1, 4, 2, 2, 5, 4, 0, 4, 6, 5, 7, 1, 5, 4, 4, 1, 0, 1, 3, 2, 7, 4, 7, 7, 6, 6, 1, 3, 6, 7, 1, 3, 2, 5, 2, 3, 0, 0, 6, 1, 4, 2, 3, 2, 4, 3, 1, 5, 0, 3, 8, 1, 8, 0, 1, 8, 6, 2, 8, 0, 6, 4, 3, 2, 3, 5, 6, 0, 2, 0, 2, 3, 0, 1, 7, 4, 3, 1, 5, 7, 8, 6, 3, 1, 1, 5, 7, 8, 6, 5, 7, 1, 5, 6, 8, 5, 6, 3, 3, 8, 0, 4, 0, 4, 6, 1, 7, 2, 3, 3, 0, 2, 7, 7, 6, 0, 6, 0, 5, 7, 7, 6, 3, 3, 5, 7, 4, 0, 0, 7, 4, 4, 4, 5, 8, 7, 6, 3, 1, 2, 3, 6, 3, 1, 0, 6, 6, 1, 3, 1, 8, 3, 7, 0, 4, 5, 4, 5, 6, 5, 3, 5, 5, 1, 2, 0, 4, 7, 7, 6, 0, 7, 5, 7, 0, 1, 3, 6, 6, 2, 0, 5, 7, 7, 7, 3, 2, 6, 6, 6, 7, 2, 8, 5, 8, 6, 8, 3, 4, 3, 4, 3, 7, 2, 5, 7, 8, 2, 1, 8, 4, 3, 4, 2, 0, 6, 8, 1, 3, 3, 3, 1, 7, 1, 5, 5, 8, 0, 8, 2, 1, 7, 2, 1, 4, 8, 6, 0, 5, 3, 5, 0, 7, 4, 7, 0, 8, 8, 4, 3, 1, 5, 8, 1, 0, 8, 8, 6, 5, 2, 7, 4, 7, 0, 4, 3, 0, 2, 1, 4, 0, 6, 7, 0, 0, 7, 4, 5, 1, 5, 1, 1, 3, 4, 2, 7, 7, 0, 4, 8, 6, 2, 6, 7, 5, 6, 7, 5, 6, 0, 7, 8, 0, 6, 2, 3, 7, 4, 2, 0, 1, 7, 7, 8, 7, 7, 5, 3, 8, 8, 8, 8, 3, 6, 0, 7, 4, 4, 2, 5, 4, 2, 0, 3, 5, 0, 3, 8, 6, 7, 6, 4, 8, 2, 6, 3, 3, 7, 5, 3, 3, 6, 3, 6, 5, 0, 1, 0, 8, 4, 8, 8, 4, 6, 7, 8, 4, 1, 8, 1, 0, 4, 3, 6, 1, 3, 1, 8, 4, 4, 3, 5, 1, 6, 4, 1, 6, 1, 7, 2, 0, 5, 5, 7, 1, 2, 0, 7, 0, 4, 3, 4, 6, 1, 5, 8, 2, 6, 6, 5, 3, 1, 0, 7, 2, 1, 1, 2, 0, 5, 4, 3, 0, 7, 8, 7, 8, 6, 7, 7, 7, 0, 1, 6, 0, 5, 1, 7, 2, 8, 3, 5, 5, 3, 8, 5, 6, 1, 5, 4, 8, 7, 8, 2, 7, 1, 5, 4, 8, 3, 1, 1, 8, 3, 8, 1, 7, 1, 4, 3, 3, 7, 2, 4, 6, 7, 6, 8, 3, 0, 7, 2, 6, 5, 3, 4, 2, 8, 3, 8, 5, 4, 6, 1, 3, 6, 2, 0, 1, 6, 0, 8, 1, 5, 3, 0, 0, 6, 2, 2, 0, 7, 4, 2, 6, 7, 6, 7, 5, 5, 1, 7, 8, 0, 7, 8, 2, 6, 4, 2, 7, 8, 6, 2, 6, 1, 3, 1, 8, 6, 8, 3, 2, 0, 8, 0, 1, 6, 7, 2, 3, 6, 2, 2, 3, 3, 7, 2, 2, 4, 0, 5, 6, 4, 7, 1, 1, 3, 2, 4, 4, 5, 2, 7, 7, 0, 1, 3, 2, 5, 2, 0, 2, 6, 4, 5, 0, 1, 0, 3, 3, 7, 6, 2, 8, 8, 6, 2, 4, 3, 2, 6, 1, 7, 8, 8, 6, 3, 2, 7, 0, 3, 6, 0, 8, 8, 3, 7, 3, 1, 7, 3, 5, 4, 0, 2, 3, 7, 5, 0, 0, 5, 8, 8, 5, 5, 5, 1, 6, 6, 8, 4, 2, 8, 7, 7, 3, 8, 8, 3, 2, 1, 2, 6, 4, 6, 0, 8, 3, 8, 6, 7, 5, 4, 1, 0, 4, 6, 6, 3, 5, 8, 8, 0, 2, 6, 3, 7, 3, 5, 4, 8, 1, 0, 6, 1, 0, 1, 5, 0, 8, 2, 0, 5, 3, 1, 6, 1, 7, 5, 7, 0, 7, 1, 8, 6, 6, 0, 3, 7, 1, 6, 5, 5, 4, 3, 4, 1, 3, 1, 3, 5, 7, 2, 4, 4, 7, 5, 8, 3, 0, 8, 1, 6, 4, 7, 3, 3, 3, 5, 3, 6, 4, 2, 1, 4, 2, 1, 1, 0, 7, 3, 4, 4, 6, 1, 8, 0, 3, 8, 3, 6, 4, 5, 5, 8, 4, 5, 5, 6, 8, 1, 4, 6, 8, 3, 1, 1, 2, 4, 2, 7, 7, 2, 3, 5, 8, 8, 8, 5, 4, 3, 2, 3, 2, 5, 8, 4, 7, 1, 0, 1, 5, 3, 4, 2, 8, 5, 5, 6, 3, 0, 2, 1, 4, 0, 4, 6, 6, 4, 8, 0, 6, 4, 5, 5, 1, 8, 2, 6, 8, 7, 3, 6, 4, 6, 1, 8, 7, 6, 1, 6, 8, 6, 5, 1, 6, 2, 2, 4, 1, 2, 3, 4, 2, 7, 6, 6, 0, 4, 2, 8, 4, 4, 8, 1, 5, 5, 0, 7, 0, 7, 4, 4, 3, 6, 1, 6, 4, 1, 0, 1, 4, 3, 0, 1, 2, 1, 7, 8, 3, 6, 6, 1, 7, 8, 6, 6, 8, 1, 4, 8, 4, 2, 2, 1, 5, 3, 5, 4, 7, 8, 5, 1, 8, 5, 7, 1, 0, 1, 4, 2, 5, 7, 0, 8, 3, 5, 3, 0, 4, 1, 8, 3, 3, 1, 8, 3, 3, 3, 5, 5, 3, 3, 8, 1, 0, 7, 1, 6, 5, 6, 6, 6, 5, 7, 7, 5, 8, 4, 8, 0, 5, 4, 4, 5, 4, 4, 1, 5, 6, 1, 2, 0, 0, 6, 8, 6, 0, 6, 7, 4, 5, 4, 8, 1, 2, 7, 1, 4, 0, 4, 1, 6, 8, 0, 7, 3, 8, 3, 1, 0, 6, 4, 8, 6, 7, 5, 5, 0, 5, 5, 0, 1, 5, 2, 1, 2, 3, 7, 4, 0, 3, 6, 3, 5, 4, 1, 5, 5, 1, 6, 8, 8, 1, 1, 2, 6, 6, 1, 1, 8, 8, 5, 5, 5, 2, 7, 4, 0, 5, 5, 2, 1, 3, 8, 7, 8, 1, 7, 5, 0, 4, 7, 1, 6, 8, 2, 3, 3, 7, 8, 3, 4, 4, 2, 0, 6, 2, 7, 7, 2, 4, 8, 6, 4, 0, 8, 7, 1, 2, 4, 4, 6, 1, 0, 2, 7, 6, 8, 3, 1, 1, 0, 3, 5, 2, 0, 7, 6, 6, 2, 1, 3, 1, 7, 7, 1, 2, 7, 0, 6, 0, 0, 1, 1, 1, 6, 3, 4, 8, 5, 3, 1, 1, 6, 7, 4, 2, 2, 8, 5, 2, 4, 3, 1, 5, 5, 3, 8, 6, 3, 6, 8, 1, 1, 7, 0, 3, 4, 4, 1, 3, 0, 4, 7, 1, 4, 3, 6, 5, 1, 8, 8, 5, 8, 6, 1, 3, 2, 6, 0, 0, 4, 8, 8, 2, 5, 1, 3, 4, 2, 0, 7, 3, 1, 4, 2, 3, 4, 1, 4, 6, 7, 7, 7, 0, 6, 1, 7, 8, 6, 6, 6, 0, 5, 3, 5, 3, 7, 7, 3, 3, 2, 4, 5, 2, 1, 7, 5, 2, 1, 2, 1, 5, 8, 6, 6, 4, 6, 2, 1, 4, 5, 5, 4, 1, 7, 6, 4, 8, 1, 3, 5, 5, 4, 2, 5, 0, 8, 8, 8, 4, 5, 8, 4, 5, 7, 7, 3, 7, 5, 3, 0, 6, 4, 0, 0, 3, 4, 7, 4, 1, 0, 0, 6, 3, 7, 5, 1, 4, 4, 6, 1, 8, 6, 4, 5, 8, 8, 6, 8, 4, 5, 0, 1, 7, 4, 3, 3, 4, 7, 2, 7, 7, 7, 2, 6, 4, 1, 7, 3, 6, 3, 8, 8, 3, 5, 4, 2, 3, 2, 2, 0, 1, 1, 3, 4, 2, 1, 0, 7, 1, 4, 2, 1, 8, 8, 5, 2, 0, 2, 3, 2, 6, 7, 4, 4, 6, 7, 2, 5, 7, 3, 2, 6, 4, 7, 5, 4, 1, 5, 5, 2, 7, 4, 3, 4, 3, 6, 0, 6, 1, 8, 5, 8, 2, 7, 4, 3, 0, 4, 2, 8, 3, 6, 2, 4, 7, 6, 5, 7, 7, 8, 1, 5, 8, 5, 5, 2, 6, 8, 5, 4, 8, 4, 0, 8, 8, 7, 2, 4, 3, 7, 0, 2, 1, 0, 2, 4, 4, 7, 0, 7, 6, 7, 1, 2, 7, 4, 7, 8, 5, 2, 2, 3, 2, 4, 3, 4, 3, 6, 5, 4, 2, 5, 8, 3, 7, 2, 8, 2, 3, 7, 4, 5, 2, 7, 6, 6, 8, 4, 2, 7, 8, 5, 6, 4, 2, 1, 2, 1, 4, 2, 4, 2, 5, 5, 2, 3, 3, 6, 7, 4, 1, 4, 8, 4, 0, 6, 6, 5, 4, 6, 8, 6, 6, 8, 7, 2, 5, 6, 8, 4, 1, 7, 8, 8, 6, 2, 3, 5, 7, 2, 3, 8, 1, 1, 4, 1, 6, 1, 1, 8, 5, 7, 1, 0, 4, 0, 6, 6, 4, 1, 6, 1, 7, 5, 6, 0, 5, 6, 1, 7, 6, 6, 6, 4, 8, 8, 6, 8, 4, 2, 7, 5, 2, 1, 5, 6, 1, 2, 8, 5, 4, 8, 4, 7, 0, 4, 8, 4, 7, 7, 1, 8, 1, 7, 4, 2, 4, 5, 8, 4, 7, 2, 5, 6, 8, 4, 4, 3, 2, 5, 6, 5, 7, 2, 3, 0, 5, 5, 7, 8, 6, 3, 2, 3, 6, 7, 8, 7, 4, 3, 1, 3, 4, 3, 4, 2, 1, 0, 2, 2, 6, 6, 2, 1, 3, 1, 2, 6, 2, 3, 8, 5, 8, 8, 6, 3, 5, 4, 4, 7, 2, 4, 7, 5, 4, 0, 0, 0, 2, 6, 0, 5, 5, 5, 1, 0, 5, 6, 3, 7, 7, 0, 6, 8, 0, 8, 2, 8, 7, 6, 8, 3, 6, 8, 4, 2, 1, 1, 3, 3, 0, 7, 5, 5, 3, 1, 5, 1, 1, 1, 7, 6, 3, 8, 4, 0, 3, 2, 4, 5, 4, 3, 7, 7, 6, 3, 7, 0, 6, 8, 5, 6, 5, 5, 6, 7, 1, 0, 0, 7, 5, 0, 5, 8, 0, 0, 1, 3, 4, 6, 8, 5, 8, 4, 2, 3, 0, 7, 7, 1, 5, 5, 3, 5, 1, 7, 0, 1, 2, 5, 0, 7, 3, 5, 0, 1, 0, 6, 7, 1, 4, 5, 6, 0, 6, 0, 2, 8, 1, 5, 2, 0, 1, 1, 2, 4, 8, 8, 3, 1, 0, 4, 3, 2, 0, 3, 3, 6, 8, 3, 2, 4, 1, 0, 6, 6, 3, 1, 8, 0, 4, 2, 5, 2, 8, 4, 8, 8, 1, 5, 5, 8, 2, 2, 3, 8, 5, 8, 8, 7, 4, 2, 8, 6, 1, 7, 2, 1, 3, 0, 0, 0, 8, 3, 7, 0, 0, 4, 7, 7, 6, 0, 1, 2, 4, 4, 6, 7, 4, 7, 2, 1, 3, 8, 2, 7, 7, 1, 3, 4, 4, 3, 0, 2, 0, 0, 1, 1, 5, 5, 0, 4, 4, 6, 7, 5, 6, 5, 7, 6, 8, 5, 2, 6, 6, 6, 2, 5, 6, 5, 5, 7, 4, 2, 4, 8, 6, 8, 5, 2, 6, 2, 2, 4, 3, 4, 7, 7, 0, 3, 0, 5, 6, 8, 4, 2, 6, 3, 0, 1, 0, 0, 8, 4, 4, 6, 1, 6, 3, 0, 8, 0, 4, 2, 4, 3, 0, 5, 8, 7, 3, 3, 6, 8, 1, 4, 6, 7, 5, 7, 7, 5, 6, 3, 5, 3, 6, 7, 8, 5, 0, 1, 5, 7, 7, 3, 2, 7, 8, 3, 4, 8, 0, 3, 6, 6, 3, 5, 2, 1, 1, 7, 7, 6, 5, 8, 0, 4, 4, 0, 3, 4, 2, 1, 4, 0, 3, 1, 2, 2, 7, 2, 5, 0, 6, 3, 6, 5, 5, 3, 4, 0, 0, 5, 7, 5, 0, 6, 6, 6, 8, 1, 6, 6, 3, 4, 7, 4, 2, 6, 5, 2, 1, 1, 8, 8, 3, 6, 6, 6, 3, 3, 6, 5, 4, 1, 8, 3, 8, 4, 4, 8, 8, 8, 8, 6, 1, 6, 8, 3, 3, 1, 2, 2, 2, 7, 0, 6, 4, 0, 6, 4, 8, 5, 8, 6, 5, 6, 6, 4, 2, 4, 1, 8, 2, 3, 5, 6, 3, 6, 5, 1, 2, 5, 0, 1, 5, 4, 7, 4, 5, 6, 2, 8, 8, 7, 7, 6, 5, 5, 8, 4, 6, 2, 1, 7, 3, 1, 2, 2, 3, 8, 0, 8, 4, 2, 1, 7, 1, 2, 0, 1, 0, 5, 5, 7, 7, 8, 4, 8, 0, 7, 7, 0, 6, 7, 8, 0, 7, 1, 1, 0, 8, 2, 6, 2, 1, 8, 4, 6, 0, 6, 3, 0, 8, 6, 3, 3, 7, 6, 1, 8, 5, 3, 4, 4, 6, 2, 0, 4, 6, 8, 6, 3, 3, 8, 1, 1, 7, 3, 2, 4, 6, 8, 1, 3, 6, 3, 0, 1, 5, 3, 8, 0, 0, 3, 3, 8, 8, 8, 6, 5, 5, 4, 3, 3, 8, 3, 1, 0, 4, 7, 1, 5, 3, 5, 4, 6, 2, 8, 7, 5, 0, 3, 1, 2, 8, 0, 4, 5, 3, 2, 7, 0, 2, 8, 0, 1, 7, 1, 2, 7, 7, 2, 3, 2, 2, 2, 7, 8, 6, 0, 4, 0, 6, 7, 1, 7, 0, 4, 1, 8, 6, 0, 5, 3, 2, 1, 0, 0, 8, 8, 1, 1, 7, 4, 8, 1, 5, 8, 8, 2, 1, 4, 7, 2, 1, 0, 6, 7, 7, 1, 3, 5, 5, 6, 3, 8, 5, 7, 6, 3, 2, 7, 6, 6, 4, 7, 3, 2, 3, 5, 2, 3, 7, 3, 8, 7, 1, 1, 5, 5, 6, 7, 8, 1, 2, 0, 1, 8, 1, 1, 4, 3, 8, 5, 0, 4, 3, 5, 2, 6, 2, 5, 4, 8, 4, 5, 6, 0, 2, 2, 3, 2, 5, 3, 5, 3, 0, 2, 6, 3, 8, 6, 7, 5, 0, 8, 5, 8, 1, 4, 1, 8, 6, 0, 8, 1, 6, 6, 5, 3, 0, 0, 4, 1, 8, 7, 7, 8, 7, 7, 4, 3, 7, 6, 0, 7, 5, 8, 5, 0, 3, 4, 2, 8, 0, 5, 2, 5, 8, 0, 5, 7, 2, 6, 3, 5, 0, 6, 8, 5, 5, 3, 8, 5, 4, 5, 0, 1, 8, 0, 1, 1, 8, 5, 1, 0, 7, 2, 6, 8, 0, 2, 2, 1, 6, 4, 5, 1, 6, 3, 8, 7, 1, 7, 8, 1, 0, 4, 3, 2, 0, 6, 0, 4, 4, 4, 8, 8, 0, 3, 6, 1, 3, 5, 0, 3, 2, 2, 5, 2, 4, 3, 3, 0, 1, 6, 4, 3, 7, 2, 7, 8, 6, 7, 6, 3, 7, 0, 0, 5, 6, 2, 3, 4, 5, 0, 8, 8, 7, 0, 5, 8, 3, 6, 3, 6, 4, 1, 3, 1, 5, 6, 8, 6, 5, 8, 1, 0, 5, 3, 0, 6, 0, 4, 5, 4, 1, 6, 0, 0, 5, 1, 2, 4, 2, 7, 7, 8, 3, 4, 7, 5, 8, 6, 7, 6, 7, 7, 0, 1, 6, 8, 0, 0, 4, 3, 0, 0, 0, 4, 4, 7, 3, 0, 4, 5, 7, 1, 5, 0, 4, 5, 7, 2, 6, 5, 6, 7, 7, 5, 0, 1, 4, 2, 1, 1, 1, 1, 6, 3, 6, 6, 5, 5, 2, 7, 2, 0, 5, 8, 4, 2, 2, 1, 2, 6, 6, 3, 0, 4, 4, 7, 8, 7, 0, 8, 3, 3, 4, 2, 0, 0, 3, 6, 1, 8, 8, 4, 8, 5, 2, 3, 5, 3, 8, 0, 5, 5, 0, 5, 5, 8, 7, 2, 0, 5, 0, 1, 1, 2, 7, 1, 1, 7, 2, 4, 3, 3, 8, 0, 3, 7, 0, 7, 5, 3, 3, 1, 4, 5, 7, 7, 3, 3, 4, 2, 4, 4, 1, 7, 8, 8, 0, 6, 2, 5, 5, 0, 4, 0, 4, 4, 2, 0, 2, 0, 7, 5, 8, 6, 1, 0, 0, 3, 3, 2, 1, 8, 5, 8, 7, 8, 2, 8, 4, 6, 5, 1, 6, 5, 2, 7, 3, 8, 7, 8, 1, 8, 4, 1, 7, 0, 7, 3, 3, 1, 2, 2, 5, 0, 3, 2, 3, 2, 0, 2, 1, 3, 1, 1, 2, 1, 2, 5, 2, 4, 8, 0, 4, 7, 3, 5, 5, 7, 8, 8, 5, 1, 8, 6, 0, 4, 4, 6, 7, 6, 1, 4, 5, 7, 1, 8, 6, 0, 6, 6, 6, 1, 4, 0, 0, 5, 7, 4, 3, 0, 7, 1, 5, 1, 2, 6, 7, 4, 5, 3, 5, 6, 5, 2, 5, 2, 2, 5, 0, 6, 7, 2, 3, 0, 2, 1, 5, 8, 0, 6, 3, 4, 2, 4, 5, 2, 4, 2, 8, 7, 0, 2, 1, 2, 7, 5, 6, 0, 4, 8, 2, 3, 4, 4, 7, 1, 1, 0, 8, 4, 4, 7, 6, 5, 7, 2, 6, 7, 3, 1, 7, 3, 4, 0, 0, 1, 7, 4, 5, 0, 0, 0, 8, 6, 5, 0, 1, 4, 8, 2, 4, 2, 6, 2, 2, 4, 3, 1, 6, 0, 2, 4, 8, 5, 4, 7, 4, 6, 3, 5, 2, 1, 6, 2, 0, 5, 0, 5, 2, 7, 7, 6, 0, 0, 6, 4, 2, 1, 3, 2, 5, 6, 4, 8, 0, 3, 4, 1, 7, 7, 3, 4, 6, 4, 3, 7, 5, 0, 0, 3, 0, 7, 4, 4, 1, 2, 4, 4, 7, 7, 7, 7, 0, 1, 0, 2, 0, 5, 8, 3, 5, 6, 4, 2, 4, 0, 3, 6, 2, 1, 7, 0, 5, 6, 8, 4, 7, 1, 0, 2, 2, 7, 5, 1, 2, 5, 3, 0, 4, 2, 2, 0, 4, 2, 8, 2, 2, 3, 2, 5, 6, 2, 4, 4, 8, 7, 8, 2, 3, 5, 8, 5, 0, 7, 3, 5, 1, 1, 5, 3, 3, 6, 0, 7, 8, 3, 8, 7, 5, 8, 7, 3, 2, 0, 8, 7, 3, 7, 1, 4, 2, 0, 2, 7, 8, 3, 3, 8, 3, 7, 0, 0, 6, 0, 8, 8, 8, 8, 8, 0, 6, 5, 3, 1, 3, 5, 3, 1, 6, 2, 8, 2, 1, 8, 1, 5, 8, 2, 2, 2, 6, 7, 4, 2, 0, 7, 3, 0, 6, 3, 4, 1, 2, 4, 2, 5, 4, 3, 6, 4, 8, 0, 6, 2, 2, 3, 0, 5, 6, 1, 8, 6, 1, 2, 6, 6, 6, 2, 2, 7, 4, 4, 1, 6, 1, 5, 0, 8, 3, 3, 2, 6, 7, 5, 0, 5, 0, 3, 0, 8, 1, 3, 2, 4, 6, 4, 8, 0, 1, 8, 0, 4, 3, 6, 5, 7, 8, 0, 2, 6, 5, 1, 1, 7, 6, 7, 7, 5, 0, 2, 7, 7, 2, 7, 6, 2, 4, 7, 6, 0, 1, 2, 2, 4, 7, 1, 4, 5, 2, 6, 4, 4, 4, 1, 2, 6, 2, 0, 8, 3, 8, 6, 8, 5, 7, 6, 7, 3, 2, 4, 0, 8, 6, 2, 0, 2, 2, 7, 3, 0, 1, 5, 4, 4, 1, 3, 0, 4, 3, 1, 7, 3, 2, 0, 0, 7, 8, 4, 8, 2, 3, 8, 6, 8, 5, 6, 0, 6, 4, 0, 4, 1, 0, 0, 7, 0, 1, 4, 3, 7, 7, 7, 8, 5, 8, 4, 2, 6, 1, 0, 6, 2, 4, 4, 1, 6, 1, 8, 0, 5, 4, 0, 2, 2, 2, 3, 0, 1, 0, 1, 4, 7, 8, 2, 0, 0, 1, 3, 0, 5, 1, 4, 0, 5, 2, 3, 4, 5, 0, 2, 7, 2, 0, 4, 4, 1, 1, 3, 4, 3, 0, 7, 4, 2, 4, 4, 4, 6, 2, 8, 2, 6, 5, 5, 5, 4, 0, 5, 4, 2, 5, 8, 8, 0, 8, 5, 3, 7, 4, 4, 7, 5, 5, 5, 6, 8, 0, 6, 0, 0, 1, 5, 4, 8, 5, 8, 4, 7, 1, 4, 7, 4, 8, 6, 7, 2, 8, 6, 0, 2, 7, 0, 1, 4, 5, 4, 4, 8, 4, 2, 7, 1, 5, 1, 4, 4, 8, 1, 3, 6, 6, 4, 4, 0, 5, 8, 6, 3, 1, 5, 4, 0, 8, 5, 4, 5, 0, 2, 4, 2, 4, 4, 1, 8, 3, 2, 4, 6, 4, 2, 5, 4, 6, 3, 1, 8, 7, 7, 1, 6, 2, 3, 5, 5, 4, 7, 3, 3, 1, 1, 2, 3, 8, 7, 1, 1, 3, 0, 5, 7, 8, 8, 8, 3, 0, 3, 6, 6, 0, 6, 6, 4, 7, 7, 1, 8, 1, 5, 5, 0, 6, 0, 8, 0, 3, 8, 1, 4, 7, 3, 7, 8, 3, 4, 6, 8, 0, 6, 7, 3, 7, 0, 0, 1, 5, 7, 6, 0, 1, 7, 1, 1, 2, 4, 8, 4, 6, 0, 7, 2, 1, 1, 3, 3, 4, 7, 3, 6, 1, 4, 1, 0, 5, 6, 6, 1, 7, 3, 7, 1, 4, 7, 5, 1, 1, 2, 3, 6, 2, 2, 4, 5, 5, 3, 8, 2, 0, 7, 6, 4, 3, 4, 2, 2, 7, 5, 4, 5, 6, 7, 5, 7, 0, 4, 8, 6, 4, 8, 5, 3, 0, 8, 5, 3, 3, 8, 7, 1, 0, 7, 3, 5, 2, 6, 8, 7, 0, 6, 3, 1, 8, 2, 3, 5, 7, 0, 2, 6, 5, 8, 8, 0, 3, 6, 0, 4, 4, 8, 2, 3, 5, 8, 3, 6, 3, 1, 6, 2, 4, 0, 3, 8, 2, 7, 5, 7, 7, 8, 4, 2, 1, 5, 5, 2, 1, 5, 1, 8, 0, 2, 0, 8, 0, 0, 2, 7, 4, 3, 2, 3, 5, 1, 1, 2, 3, 7, 3, 7, 4, 8, 1, 0, 2, 1, 3, 2, 4, 3, 5, 0, 7, 5, 0, 7, 3, 3, 0, 6, 4, 5, 2, 4, 0, 1, 4, 8, 6, 0, 2, 0, 3, 7, 0, 4, 0, 3, 6, 2, 0, 8, 8, 4, 4, 7, 5, 0, 8, 0, 4, 2, 8, 5, 8, 8, 6, 5, 7, 1, 0, 4, 6, 0, 3, 8, 2, 6, 1, 6, 0, 4, 8, 8, 5, 7, 6, 6, 5, 6, 8, 5, 7, 2, 2, 3, 7, 5, 1, 8, 0, 3, 5, 6, 4, 5, 1, 0, 0, 1, 1, 4, 7, 0, 4, 0, 5, 2, 6, 4, 0, 7, 0, 1, 2, 6, 0, 6, 5, 6, 6, 7, 2, 0, 3, 5, 7, 6, 7, 7, 3, 7, 3, 7, 2, 4, 4, 0, 2, 1, 4, 6, 7, 0, 8, 6, 6, 6, 2, 3, 6, 6, 8, 0, 1, 6, 6, 3, 3, 2, 0, 3, 6, 0, 8, 7, 8, 8, 6, 7, 2, 3, 5, 1, 5, 7, 8, 4, 3, 0, 6, 4, 7, 3, 5, 0, 4, 2, 2, 0, 4, 5, 1, 1, 1, 3, 3, 0, 6, 5, 6, 5, 4, 4, 1, 1, 6, 3, 6, 4, 8, 5, 7, 6, 2, 0, 0, 0, 8, 3, 0, 8, 2, 6, 4, 0, 5, 1, 8, 4, 7, 7, 8, 4, 5, 7, 8, 8, 8, 5, 7, 8, 3, 3, 4, 4, 1, 3, 3, 7, 4, 2, 2, 2, 3, 6, 8, 1, 4, 7, 0, 5, 5, 3, 7, 2, 6, 5, 2, 3, 2, 8, 0, 1, 5, 7, 2, 5, 6, 2, 0, 8, 7, 5, 7, 4, 8, 7, 4, 0, 4, 8, 7, 4, 8, 3, 0, 2, 3, 4, 5, 0, 2, 6, 2, 0, 5, 6, 2, 8, 8, 5, 8, 6, 3, 7, 6, 3, 4, 8, 2, 7, 5, 1, 5, 0, 0, 5, 8, 8, 0, 8, 3, 2, 0, 8, 1, 0, 8, 7, 5, 3, 7, 0, 8, 1, 5, 6, 4, 0, 0, 5, 7, 5, 3, 7, 1, 2, 0, 4, 5, 7, 4, 4, 3, 5, 1, 8, 0, 5, 3, 0, 3, 5, 0, 7, 8, 2, 2, 3, 5, 5, 4, 2, 2, 2, 3, 1, 5, 5, 0, 1, 6, 5, 8, 1, 0, 3, 4, 1, 5, 4, 8, 2, 1, 6, 2, 6, 0, 8, 4, 6, 7, 3, 7, 5, 4, 8, 0, 4, 2, 2, 6, 4, 3, 1, 0, 7, 1, 8, 8, 0, 1, 5, 6, 5, 3, 7, 2, 5, 5, 6, 7, 0, 3, 8, 2, 5, 2, 1, 6, 1, 8, 8, 4, 8, 5, 1, 6, 7, 0, 1, 0, 6, 3, 3, 5, 1, 7, 1, 2, 2, 7, 7, 8, 5, 3, 7, 1, 4, 5, 4, 8, 4, 2, 5, 4, 7, 4, 5, 3, 3, 3, 0, 7, 8, 0, 8, 5, 4, 1, 0, 1, 7, 4, 6, 2, 1, 8, 1, 6, 6, 0, 6, 6, 7, 5, 1, 4, 7, 1, 6, 6, 7, 7, 6, 1, 2, 3, 4, 2, 4, 2, 6, 1, 2, 8, 7, 2, 6, 0, 4, 6, 0, 3, 8, 2, 6, 2, 1, 6, 5, 6, 1, 0, 3, 2, 8, 8, 5, 6, 1, 8, 4, 4, 7, 1, 8, 4, 8, 8, 1, 3, 6, 2, 6, 1, 8, 6, 1, 5, 8, 4, 8, 4, 4, 7, 6, 0, 2, 8, 7, 0, 2, 2, 0, 8, 1, 5, 2, 4, 7, 3, 1, 7, 8, 4, 8, 3, 6, 7, 3, 3, 6, 3, 6, 8, 0, 6, 2, 1, 6, 7, 5, 8, 7, 1, 2, 6, 0, 0, 7, 5, 8, 3, 5, 5, 0, 0, 2, 4, 8, 4, 7, 5, 8, 5, 5, 1, 1, 4, 2, 5, 1, 8, 2, 8, 2, 4, 2, 3, 2, 2, 6, 3, 4, 6, 3, 4, 6, 4, 6, 4, 4, 5, 1, 2, 6, 4, 0, 2, 3, 8, 3, 5, 4, 6, 3, 3, 4, 4, 6, 4, 1, 4, 0, 8, 7, 0, 5, 7, 6, 2, 5, 3, 1, 7, 5, 6, 4, 1, 2, 3, 0, 3, 8, 0, 8, 5, 6, 8, 4, 0, 2, 3, 7, 1, 4, 6, 5, 4, 5, 0, 3, 0, 8, 3, 1, 6, 1, 5, 6, 8, 7, 6, 1, 2, 6, 6, 4, 2, 2, 4, 5, 3, 6, 1, 4, 0, 1, 1, 1, 1, 4, 3, 8, 4, 1, 6, 5, 8, 1, 6, 1, 4, 3, 0, 0, 3, 2, 7, 3, 8, 7, 4, 0, 7, 7, 2, 8, 5, 6, 5, 1, 3, 3, 5, 2, 0, 6, 0, 7, 8, 0, 4, 0, 6, 2, 1, 5, 4, 2, 6, 0, 0, 1, 8, 1, 3, 1, 1, 8, 1, 6, 7, 3, 4, 6, 2, 7, 2, 2, 0, 0, 3, 1, 7, 7, 6, 4, 0, 3, 1, 7, 7, 2, 7, 1, 1, 1, 3, 4, 7, 4, 2, 4, 7, 5, 2, 4, 3, 4, 2, 8, 8, 7, 5, 7, 5, 5, 8, 8, 4, 1, 0, 0, 1, 7, 5, 1, 7, 0, 6, 3, 2, 0, 0, 0, 4, 2, 8, 7, 4, 2, 2, 8, 5, 1, 8, 1, 3, 3, 0, 5, 1, 8, 8, 1, 4, 8, 0, 2, 3, 7, 2, 4, 4, 1, 3, 4, 0, 2, 5, 3, 7, 1, 4, 1, 7, 0, 7, 2, 0, 5, 3, 5, 2, 5, 2, 2, 6, 8, 2, 5, 8, 7, 5, 4, 3, 0, 5, 3, 0, 3, 6, 7, 7, 7, 1, 5, 1, 4, 1, 6, 0, 3, 5, 4, 1, 1, 0, 0, 8, 1, 3, 4, 8, 8, 6, 0, 2, 6, 2, 2, 4, 0, 1, 0, 7, 3, 5, 7, 3, 0, 7, 3, 8, 3, 5, 2, 8, 8, 3, 0, 1, 8, 1, 8, 2, 8, 1, 4, 3, 0, 3, 5, 4, 7, 1, 3, 4, 8, 0, 8, 2, 2, 7, 0, 5, 5, 6, 5, 4, 8, 1, 0, 1, 6, 7, 7, 5, 3, 2, 5, 6, 4, 4, 1, 6, 4, 1, 5, 1, 2, 7, 4, 2, 7, 8, 7, 4, 5, 4, 2, 7, 1, 2, 8, 1, 5, 0, 6, 1, 3, 4, 0, 2, 8, 6, 6, 6, 0, 7, 8, 3, 6, 2, 5, 1, 3, 5, 0, 0, 1, 4, 1, 0, 8, 7, 0, 5, 8, 5, 6, 4, 3, 1, 0, 7, 6, 0, 7, 6, 6, 0, 4, 7, 4, 1, 0, 5, 8, 3, 4, 7, 4, 3, 2, 3, 2, 4, 8, 2, 2, 5, 2, 7, 3, 0, 3, 1, 4, 8, 0, 1, 0, 0, 2, 6, 3, 5, 2, 5, 0, 1, 4, 8, 0, 3, 2, 8, 3, 7, 7, 4, 8, 6, 1, 8, 3, 7, 8, 7, 2, 1, 7, 7, 1, 1, 6, 4, 4, 0, 5, 6, 1, 2, 8, 6, 8, 3, 1, 0, 0, 5, 4, 5, 2, 1, 8, 1, 2, 7, 6, 3, 1, 3, 7, 8, 6, 1, 1, 4, 2, 1, 6, 8, 6, 2, 3, 0, 7, 7, 7, 5, 2, 6, 4, 8, 5, 1, 5, 6, 3, 6, 2, 0, 7, 4, 0, 8, 3, 6, 2, 8, 0, 0, 7, 6, 3, 3, 3, 7, 4, 8, 2, 7, 6, 3, 8, 6, 4, 7, 5, 5, 8, 6, 5, 7, 4, 8, 7, 2, 0, 7, 7, 0, 5, 4, 1, 3, 6, 4, 1, 7, 5, 3, 2, 3, 1, 0, 6, 0, 3, 0, 3, 6, 3, 6, 2, 6, 1, 0, 4, 7, 4, 0, 8, 7, 6, 8, 0, 8, 5, 4, 4, 5, 3, 7, 3, 3, 7, 2, 0, 4, 1, 2, 5, 1, 8, 3, 7, 2, 0, 1, 0, 7, 7, 3, 8, 7, 8, 6, 5, 2, 4, 5, 6, 5, 2, 0, 2, 5, 8, 3, 5, 2, 1, 6, 3, 8, 4, 8, 2, 8, 2, 1, 2, 4, 0, 5, 2, 6, 7, 1, 5, 3, 7, 1, 6, 6, 7, 4, 4, 7, 2, 8, 0, 7, 8, 2, 2, 7, 2, 0, 2, 3, 1, 1, 2, 6, 8, 7, 4, 8, 4, 8, 4, 2, 3, 4, 5, 3, 7, 2, 7, 8, 2, 7, 4, 1, 1, 1, 3, 6, 7, 0, 4, 7, 6, 2, 0, 3, 6, 8, 0, 3, 1, 2, 5, 4, 2, 3, 7, 2, 4, 3, 7, 1, 5, 8, 6, 2, 2, 6, 5, 7, 1, 5, 2, 0, 1, 3, 0, 3, 4, 0, 5, 6, 2, 7, 0, 0, 1, 8, 8, 8, 4, 7, 3, 3, 0, 2, 6, 2, 1, 0, 8, 4, 7, 5, 1, 8, 5, 1, 3, 4, 2, 7, 5, 8, 7, 6, 7, 3, 0, 1, 2, 8, 4, 8, 3, 4, 1, 8, 5, 4, 1, 8, 0, 1, 8, 7, 5, 3, 2, 0, 1, 3, 1, 0, 1, 0, 8, 3, 6, 5, 5, 7, 3, 1, 8, 4, 4, 7, 3, 7, 3, 0, 4, 3, 6, 8, 2, 1, 5, 3, 0, 5, 4, 4, 3, 6, 7, 3, 8, 1, 2, 4, 7, 2, 2, 4, 2, 7, 2, 3, 2, 1, 8, 1, 6, 0, 6, 2, 4, 1, 2, 6, 1, 6, 5, 7, 2, 0, 7, 7, 6, 6, 6, 5, 1, 2, 3, 1, 7, 4, 5, 2, 1, 1, 2, 5, 5, 5, 7, 5, 8, 3, 5, 5, 2, 0, 7, 0, 0, 6, 2, 3, 3, 8, 0, 6, 7, 5, 4, 4, 6, 0, 0, 8, 1, 4, 4, 6, 2, 2, 2, 0, 7, 6, 1, 8, 3, 8, 6, 8, 3, 6, 4, 3, 1, 0, 0, 1, 7, 8, 1, 0, 0, 4, 6, 7, 3, 2, 3, 7, 5, 7, 1, 3, 2, 5, 1, 5, 3, 8, 0, 1, 0, 3, 1, 2, 4, 8, 3, 6, 5, 1, 4, 7, 7, 6, 1, 7, 0, 0, 8, 6, 5, 3, 0, 0, 0, 5, 6, 8, 1, 2, 5, 4, 2, 0, 7, 0, 5, 2, 1, 4, 2, 7, 0, 4, 0, 0, 0, 4, 0, 6, 1, 2, 6, 0, 8, 6, 8, 2, 6, 0, 1, 4, 3, 1, 4, 3, 3, 7, 4, 2, 4, 4, 5, 5, 5, 7, 8, 4, 0, 4, 3, 4, 6, 5, 2, 3, 6, 6, 2, 8, 3, 6, 7, 2, 0, 3, 1, 0, 1, 5, 1, 2, 0, 8, 6, 2, 7, 0, 5, 0, 1, 5, 5, 3, 4, 7, 2, 4, 4, 1, 6, 7, 0, 6, 5, 3, 0, 1, 4, 4, 4, 2, 5, 2, 4, 0, 8, 1, 0, 4, 7, 6, 2, 5, 1, 5, 8, 5, 4, 2, 5, 3, 3, 4, 4, 5, 6, 5, 1, 6, 4, 5, 0, 5, 1, 8, 6, 8, 5, 0, 5, 2, 8, 3, 6, 7, 7, 6, 4, 2, 8, 0, 4, 4, 7, 6, 7, 0, 5, 5, 1, 6, 0, 0, 5, 6, 6, 8, 5, 5, 4, 0, 0, 8, 6, 6, 2, 0, 8, 1, 7, 5, 3, 4, 7, 5, 0, 5, 0, 6, 1, 5, 3, 6, 0, 2, 1, 5, 4, 2, 8, 4, 5, 4, 7, 0, 7, 5, 2, 3, 6, 2, 6, 8, 2, 2, 7, 3, 6, 8, 3, 6, 2, 1, 3, 2, 5, 5, 1, 3, 1, 2, 5, 0, 3, 3, 0, 4, 8, 5, 2, 7, 1, 3, 1, 3, 5, 7, 0, 3, 2, 0, 7, 8, 7, 1, 6, 1, 4, 6, 6, 7, 6, 7, 3, 4, 7, 7, 5, 3, 8, 6, 3, 0, 7, 7, 1, 3, 1, 8, 8, 8, 2, 6, 8, 7, 3, 2, 5, 2, 6, 0, 3, 6, 5, 2, 3, 2, 1, 2, 1, 3, 1, 7, 0, 0, 6, 8, 7, 3, 4, 2, 4, 2, 6, 8, 4, 2, 1, 2, 3, 2, 4, 2, 0, 4, 3, 1, 3, 2, 1, 2, 0, 1, 2, 3, 1, 7, 6, 8, 8, 0, 2, 4, 7, 2, 0, 1, 7, 1, 0, 5, 2, 0, 2, 0, 6, 4, 6, 2, 8, 8, 0, 2, 7, 2, 6, 7, 3, 6, 1, 3, 4, 1, 3, 2, 5, 3, 0, 3, 1, 7, 3, 1, 1, 3, 6, 0, 1, 0, 2, 1, 8, 0, 0, 4, 0, 7, 3, 2, 3, 1, 6, 3, 7, 2, 5, 7, 6, 7, 1, 4, 0, 8, 7, 5, 7, 7, 5, 8, 6, 2, 1, 1, 6, 7, 4, 3, 2, 0, 3, 0, 0, 1, 5, 6, 0, 7, 5, 1, 5, 2, 3, 4, 1, 0, 0, 0, 3, 8, 4, 7, 2, 7, 7, 3, 7, 3, 3, 8, 4, 7, 3, 6, 8, 6, 3, 8, 6, 6, 1, 3, 1, 1, 1, 3, 4, 8, 7, 5, 1, 8, 1, 0, 1, 8, 8, 7, 6, 8, 6, 4, 3, 3, 4, 4, 7, 8, 1, 8, 6, 7, 3, 0, 1, 5, 0, 7, 7, 3, 1, 6, 6, 6, 1, 7, 1, 7, 4, 6, 1, 8, 5, 4, 8, 5, 7, 3, 3, 3, 5, 3, 6, 8, 0, 1, 0, 2, 1, 5, 6, 1, 7, 5, 3, 4, 6, 6, 3, 2, 8, 0, 1, 0, 5, 6, 7, 3, 5, 8, 6, 1, 2, 3, 2, 8, 2, 3, 3, 0, 3, 3, 6, 0, 2, 4, 5, 3, 5, 3, 1, 0, 8, 6, 7, 0, 8, 5, 4, 8, 0, 1, 2, 5, 2, 8, 0, 5, 7, 3, 2, 2, 5, 1, 6, 3, 8, 8, 8, 3, 4, 3, 8, 3, 1, 7, 8, 8, 3, 3, 0, 8, 5, 8, 4, 6, 6, 8, 3, 4, 3, 1, 7, 3, 2, 6, 3, 6, 1, 4, 7, 0, 6, 8, 1, 4, 4, 5, 2, 5, 2, 1, 3, 8, 3, 2, 1, 7, 4, 2, 2, 4, 7, 7, 0, 2, 0, 8, 4, 8, 3, 3, 2, 8, 2, 6, 6, 2, 8, 7, 0, 5, 3, 3, 5, 4, 3, 3, 0, 3, 8, 3, 0, 8, 7, 5, 3, 2, 2, 7, 5, 0, 0, 7, 8, 8, 0, 8, 1, 3, 1, 1, 8, 4, 1, 6, 0, 8, 5, 7, 6, 2, 2, 3, 2, 4, 0, 7, 3, 4, 0, 5, 1, 1, 2, 2, 5, 0, 3, 6, 6, 1, 4, 0, 6, 4, 6, 0, 7, 0, 3, 6, 8, 5, 8, 5, 7, 4, 5, 4, 1, 0, 4, 6, 2, 1, 2, 3, 8, 2, 8, 0, 1, 1, 4, 3, 2, 4, 4, 1, 5, 0, 3, 2, 7, 1, 1, 7, 5, 3, 4, 1, 8, 4, 1, 3, 8, 5, 5, 3, 2, 6, 3, 5, 7, 7, 7, 5, 2, 1, 6, 7, 6, 2, 5, 4, 4, 4, 8, 8, 3, 3, 4, 4, 1, 2, 6, 5, 6, 4, 2, 2, 6, 5, 1, 4, 6, 5, 4, 0, 0, 3, 2, 0, 5, 8, 0, 1, 8, 7, 8, 7, 5, 2, 2, 7, 5, 6, 4, 1, 0, 6, 5, 6, 8, 2, 0, 5, 2, 6, 6, 0, 4, 8, 5, 1, 4, 4, 2, 3, 5, 1, 0, 7, 2, 3, 2, 3, 7, 0, 0, 6, 2, 5, 7, 6, 3, 6, 0, 1, 8, 0, 8, 3, 6, 6, 2, 4, 1, 4, 5, 4, 1, 6, 0, 6, 2, 4, 0, 6, 5, 6, 6, 6, 8, 2, 1, 2, 0, 7, 7, 5, 7, 3, 6, 2, 7, 1, 1, 8, 5, 4, 5, 8, 4, 8, 8, 3, 4, 0, 3, 7, 5, 4, 0, 8, 1, 1, 8, 5, 3, 4, 6, 4, 4, 8, 7, 8, 3, 7, 1, 2, 3, 2, 3, 8, 7, 4, 2, 8, 7, 6, 6, 6, 1, 8, 0, 8, 6, 4, 6, 4, 8, 3, 7, 3, 1, 2, 2, 8, 4, 2, 8, 2, 2, 2, 7, 6, 8, 3, 1, 6, 8, 1, 3, 0, 7, 1, 0, 6, 5, 5, 8, 2, 6, 8, 5, 3, 5, 1, 8, 0, 8, 3, 2, 2, 8, 1, 6, 5, 5, 4, 3, 3, 2, 1, 4, 2, 4, 4, 8, 3, 0, 5, 0, 4, 2, 0, 5, 7, 5, 2, 6, 1, 3, 5, 0, 3, 1, 5, 5, 1, 8, 5, 7, 5, 6, 8, 4, 6, 1, 5, 6, 0, 6, 4, 8, 6, 7, 1, 1, 1, 5, 6, 7, 2, 1, 8, 6, 2, 5, 7, 2, 1, 8, 7, 1, 0, 3, 8, 7, 0, 6, 4, 5, 2, 1, 7, 0, 7, 6, 7, 0, 6, 4, 4, 4, 1, 1, 3, 3, 5, 8, 3, 6, 3, 7, 3, 2, 0, 2, 6, 7, 0, 7, 4, 0, 8, 2, 3, 4, 0, 0, 7, 6, 5, 0, 2, 8, 3, 3, 3, 0, 6, 5, 7, 1, 8, 2, 7, 6, 1, 3, 0, 0, 8, 3, 8, 7, 8, 3, 7, 5, 3, 1, 5, 4, 4, 2, 8, 6, 1, 8, 8, 3, 7, 1, 5, 1, 7, 5, 8, 6, 2, 1, 4, 7, 6, 1, 2, 2, 8, 3, 0, 5, 6, 6, 8, 0, 5, 8, 2, 6, 4, 6, 8, 1, 6, 6, 0, 7, 8, 5, 8, 2, 5, 5, 7, 1, 0, 8, 8, 8, 6, 8, 6, 0, 2, 2, 5, 3, 0, 3, 8, 2, 2, 1, 3, 4, 2, 8, 5, 2, 4, 8, 0, 8, 0, 3, 7, 3, 3, 2, 2, 3, 6, 7, 0, 0, 2, 7, 3, 6, 4, 1, 5, 3, 1, 6, 7, 8, 5, 5, 1, 6, 8, 3, 1, 5, 0, 1, 4, 1, 4, 6, 6, 4, 6, 7, 1, 6, 0, 6, 6, 7, 8, 7, 0, 3, 4, 8, 5, 4, 6, 2, 7, 6, 2, 6, 8, 1, 3, 7, 8, 4, 6, 0, 1, 2, 8, 7, 4, 5, 0, 6, 6, 2, 3, 1, 0, 2, 7, 5, 4, 2, 8, 5, 7, 8, 2, 0, 3, 0, 0, 6, 3, 7, 6, 1, 4, 3, 6, 2, 5, 2, 8, 3, 7, 1, 2, 6, 5, 0, 5, 2, 7, 3, 3, 5, 8, 0, 0, 4, 2, 6, 4, 7, 3, 1, 3, 2, 3, 4, 8, 2, 1, 2, 2, 2, 2, 4, 0, 3, 8, 4, 3, 3, 0, 2, 2, 3, 0, 4, 2, 7, 8, 3, 6, 4, 8, 7, 0, 0, 3, 6, 7, 2, 0, 5, 1, 2, 4, 8, 7, 1, 6, 7, 1, 4, 8, 2, 8, 5, 8, 0, 2, 0, 5, 1, 5, 6, 7, 0, 5, 3, 7, 5, 6, 8, 0, 7, 4, 3, 6, 3, 5, 0, 8, 2, 1, 3, 5, 0, 7, 1, 2, 2, 7, 1, 1, 5, 2, 4, 7, 6, 3, 4, 4, 0, 6, 4, 1, 5, 8, 7, 5, 2, 1, 8, 1, 2, 4, 0, 5, 8, 1, 1, 8, 6, 5, 6, 6, 7, 4, 3, 1, 8, 4, 8, 7, 1, 8, 1, 3, 3, 8, 1, 8, 5, 6, 0, 3, 4, 4, 8, 1, 2, 0, 6, 5, 5, 3, 8, 0, 5, 3, 1, 5, 1, 7, 6, 3, 2, 1, 6, 2, 8, 3, 0, 1, 7, 5, 6, 8, 0, 2, 0, 5, 6, 7, 7, 0, 1, 8, 4, 7, 8, 2, 1, 6, 3, 5, 3, 6, 8, 0, 8, 7, 6, 8, 5, 8, 2, 5, 2, 2, 5, 0, 4, 0, 0, 0, 1, 7, 3, 2, 6, 8, 3, 7, 2, 0, 1, 7, 7, 5, 5, 4, 1, 1, 8, 0, 0, 7, 2, 2, 8, 4, 5, 5, 4, 5, 3, 2, 5, 4, 8, 5, 8, 6, 6, 0, 0, 2, 6, 2, 1, 6, 7, 3, 2, 8, 6, 5, 4, 1, 4, 0, 3, 1, 3, 6, 1, 8, 8, 0, 4, 8, 8, 6, 8, 2, 5, 4, 4, 1, 4, 3, 3, 4, 5, 6, 0, 8, 0, 8, 1, 7, 3, 1, 8, 8, 0, 3, 5, 0, 2, 6, 0, 7, 5, 2, 3, 7, 2, 5, 6, 6, 6, 6, 7, 1, 3, 0, 5, 1, 1, 1, 2, 7, 5, 0, 1, 4, 1, 7, 1, 8, 0, 1, 5, 8, 1, 6, 5, 6, 3, 7, 8, 5, 8, 3, 1, 2, 7, 8, 1, 5, 8, 1, 1, 0, 5, 1, 8, 2, 2, 3, 8, 7, 2, 2, 4, 2, 5, 0, 5, 0, 2, 8, 4, 3, 0, 4, 1, 8, 7, 2, 8, 3, 5, 1, 5, 7, 0, 6, 3, 5, 7, 0, 5, 8, 2, 7, 7, 7, 8, 2, 5, 8, 6, 0, 2, 0, 0, 1, 3, 6, 1, 8, 5, 5, 3, 8, 1, 3, 0, 6, 6, 8, 0, 1, 7, 7, 7, 6, 0, 0, 8, 7, 5, 8, 0, 7, 2, 7, 3, 6, 7, 1, 4, 0, 4, 1, 7, 1, 5, 7, 0, 5, 7, 8, 5, 8, 2, 5, 6, 4, 4, 4, 2, 7, 5, 4, 0, 5, 3, 3, 1, 1, 5, 0, 6, 1, 3, 3, 4, 1, 6, 3, 3, 2, 1, 3, 6, 5, 3, 2, 7, 1, 0, 2, 0, 7, 4, 7, 2, 2, 4, 0, 0, 4, 4, 6, 4, 7, 7, 8, 3, 6, 8, 5, 2, 3, 5, 6, 1, 7, 7, 8, 0, 3, 0, 7, 4, 7, 1, 3, 4, 4, 3, 3, 3, 4, 6, 5, 8, 5, 3, 1, 6, 5, 1, 2, 7, 0, 1, 5, 5, 4, 0, 3, 6, 4, 4, 7, 2, 8, 4, 8, 0, 2, 7, 7, 1, 2, 1, 4, 6, 4, 1, 0, 0, 4, 7, 8, 0, 3, 2, 5, 8, 7, 2, 3, 7, 7, 4, 8, 5, 0, 4, 7, 3, 2, 1, 1, 8, 3, 1, 1, 2, 7, 8, 3, 0, 0, 8, 3, 6, 4, 6, 4, 3, 6, 6, 3, 2, 5, 3, 8, 8, 8, 6, 5, 0, 8, 7, 2, 5, 8, 2, 1, 6, 5, 7, 5, 5, 1, 1, 1, 6, 1, 3, 1, 7, 2, 5, 5, 2, 7, 4, 3, 0, 5, 3, 6, 8, 2, 6, 2, 4, 4, 5, 7, 0, 4, 6, 5, 2, 2, 6, 4, 0, 8, 6, 0, 0, 2, 7, 7, 4, 3, 7, 1, 6, 1, 6, 7, 4, 4, 8, 1, 3, 7, 5, 5, 6, 5, 7, 7, 5, 2, 2, 6, 0, 4, 3, 1, 6, 5, 0, 0, 6, 5, 6, 4, 6, 4, 2, 0, 0, 4, 8, 8, 4, 6, 7, 3, 4, 3, 2, 6, 7, 2, 4, 5, 5, 5, 8, 8, 1, 8, 1, 5, 3, 4, 6, 3, 1, 6, 5, 0, 8, 8, 3, 0, 3, 8, 0, 8, 6, 4, 0, 8, 4, 8, 6, 1, 3, 4, 6, 4, 1, 3, 3, 7, 4, 8, 5, 0, 8, 7, 4, 5, 5, 1, 2, 1, 6, 2, 7, 5, 8, 2, 7, 7, 4, 3, 4, 0, 1, 7, 0, 5, 3, 7, 3, 6, 0, 6, 0, 2, 4, 8, 8, 8, 0, 1, 4, 6, 1, 1, 6, 8, 0, 7, 0, 8, 6, 2, 1, 6, 8, 5, 4, 8, 4, 2, 3, 1, 3, 2, 1, 8, 6, 0, 6, 7, 2, 7, 4, 6, 3, 1, 6, 8, 4, 2, 0, 2, 8, 7, 6, 2, 2, 5, 0, 0, 6, 2, 4, 5, 6, 5, 6, 4, 6, 5, 7, 5, 7, 8, 5, 8, 5, 7, 7, 4, 5, 7, 8, 5, 6, 6, 4, 7, 5, 1, 7, 7, 4, 7, 3, 5, 2, 3, 5, 4, 6, 6, 8, 3, 6, 3, 6, 8, 4, 1, 5, 4, 1, 2, 1, 8, 7, 7, 3, 0, 0, 6, 4, 7, 8, 3, 6, 4, 3, 4, 1, 4, 8, 4, 6, 8, 5, 7, 2, 7, 6, 5, 3, 6, 6, 4, 4, 4, 3, 2, 1, 3, 2, 0, 7, 3, 2, 7, 5, 8, 6, 8, 3, 1, 5, 3, 8, 8, 2, 5, 5, 2, 0, 8, 4, 7, 3, 2, 3, 3, 4, 3, 0, 6, 6, 5, 3, 4, 3, 4, 7, 7, 1, 8, 2, 3, 1, 7, 3, 8, 6, 0, 8, 1, 5, 6, 6, 6, 4, 3, 0, 3, 5, 5, 5, 5, 7, 8, 3, 8, 7, 0, 1, 1, 4, 4, 6, 5, 6, 3, 7, 8, 7, 5, 2, 3, 1, 6, 3, 2, 2, 1, 7, 6, 3, 8, 2, 4, 4, 1, 3, 4, 3, 2, 6, 4, 6, 1, 3, 2, 7, 6, 2, 1, 0, 7, 8, 6, 5, 8, 2, 1, 8, 2, 6, 1, 2, 4, 0, 0, 4, 4, 7, 8, 7, 2, 2, 2, 0, 6, 8, 6, 5, 2, 2, 2, 0, 7, 2, 4, 6, 1, 1, 6, 1, 6, 4, 5, 0, 8, 0, 0, 5, 8, 4, 5, 5, 4, 7, 7, 6, 5, 5, 5, 7, 4, 7, 7, 2, 4, 0, 6, 2, 1, 5, 5, 1, 4, 5, 1, 7, 0, 3, 8, 1, 8, 7, 7, 7, 5, 7, 5, 4, 8, 2, 5, 6, 3, 7, 4, 4, 4, 8, 5, 6, 1, 7, 8, 0, 8, 8, 4, 6, 1, 3, 2, 3, 5, 3, 3, 1, 6, 3, 4, 0, 1, 5, 0, 4, 6, 3, 8, 1, 3, 0, 0, 0, 0, 7, 8, 6, 1, 6, 3, 2, 7, 8, 7, 1, 2, 7, 4, 4, 2, 1, 4, 6, 0, 6, 1, 6, 6, 6, 1, 4, 5, 2, 0, 6, 0, 1, 1, 4, 5, 4, 3, 8, 7, 3, 4, 3, 8, 7, 6, 1, 0, 4, 8, 8, 2, 5, 4, 4, 5, 6, 5, 1, 0, 1, 7, 0, 2, 2, 6, 3, 3, 0, 4, 2, 0, 4, 3, 2, 7, 8, 8, 1, 2, 4, 2, 8, 3, 7, 1, 2, 2, 6, 4, 5, 3, 6, 5, 0, 5, 8, 6, 8, 8, 3, 4, 7, 7, 3, 2, 7, 7, 2, 7, 8, 4, 7, 0, 1, 2, 1, 1, 7, 0, 5, 7, 6, 6, 0, 8, 2, 8, 5, 6, 1, 6, 5, 7, 4, 1, 7, 3, 3, 6, 4, 7, 0, 7, 8, 8, 1, 2, 3, 3, 3, 5, 5, 6, 2, 6, 1, 5, 3, 0, 8, 7, 7, 7, 4, 1, 2, 5, 5, 3, 7, 5, 6, 3, 7, 7, 7, 0, 7, 3, 0, 4, 8, 8, 6, 8, 0, 1, 7, 0, 0, 2, 4, 2, 8, 4, 6, 4, 6, 7, 8, 1, 1, 2, 6, 3, 0, 6, 7, 8, 8, 2, 3, 4, 0, 3, 8, 8, 0, 1, 2, 0, 3, 3, 4, 7, 2, 0, 5, 2, 6, 2, 6, 8, 5, 7, 3, 5, 1, 6, 0, 1, 2, 0, 0, 1, 4, 2, 0, 1, 4, 3, 4, 1, 2, 3, 6, 3, 2, 0, 5, 1, 6, 2, 5, 5, 0, 4, 5, 0, 0, 7, 6, 0, 3, 7, 0, 3, 5, 1, 1, 2, 5, 0, 6, 4, 6, 7, 2, 5, 5, 2, 3, 0, 3, 3, 6, 6, 5, 3, 0, 6, 6, 3, 5, 3, 0, 7, 3, 2, 0, 7, 3, 5, 4, 2, 2, 8, 5, 6, 6, 7, 6, 8, 6, 1, 1, 4, 4, 7, 6, 8, 8, 8, 3, 7, 0, 6, 1, 1, 1, 0, 6, 1, 3, 6, 5, 6, 8, 3, 0, 0, 0, 7, 5, 1, 4, 4, 4, 4, 1, 2, 2, 0, 7, 1, 6, 8, 0, 7, 6, 5, 5, 7, 8, 6, 1, 8, 0, 6, 3, 6, 8, 1, 8, 7, 6, 0, 8, 8, 3, 5, 4, 0, 1, 8, 3, 0, 5, 5, 3, 0, 7, 3, 2, 7, 1, 4, 1, 3, 0, 3, 6, 2, 6, 8, 1, 1, 6, 8, 8, 4, 3, 4, 4, 2, 0, 8, 0, 4, 8, 0, 8, 8, 0, 1, 8, 3, 7, 2, 3, 3, 7, 8, 8, 1, 2, 3, 8, 3, 4, 1, 0, 8, 0, 0, 5, 1, 8, 6, 2, 6, 5, 8, 1, 4, 6, 8, 0, 4, 3, 0, 3, 2, 1, 0, 0, 4, 8, 2, 4, 2, 5, 6, 3, 5, 3, 3, 4, 5, 3, 3, 0, 3, 7, 4, 0, 2, 0, 6, 7, 0, 8, 4, 7, 6, 4, 4, 5, 1, 5, 5, 1, 7, 7, 7, 4, 0, 6, 3, 7, 2, 8, 6, 8, 8, 3, 7, 4, 6, 8, 3, 7, 7, 6, 8, 5, 8, 1, 1, 6, 2, 5, 0, 6, 0, 0, 6, 5, 8, 6, 3, 1, 6, 4, 5, 2, 5, 4, 1, 7, 6, 3, 4, 0, 4, 7, 5, 6, 5, 4, 6, 6, 5, 0, 3, 6, 4, 5, 1, 8, 7, 4, 0, 2, 6, 2, 5, 8, 7, 7, 8, 3, 7, 2, 6, 8, 0, 4, 6, 5, 1, 3, 5, 6, 5, 0, 0, 5, 5, 0, 0, 5, 3, 7, 2, 8, 2, 8, 2, 0, 3, 0, 4, 1, 3, 0, 6, 0, 5, 1, 6, 0, 5, 7, 3, 2, 7, 8, 2, 4, 6, 6, 5, 1, 7, 3, 6, 3, 6, 7, 2, 0, 7, 1, 4, 6, 1, 1, 5, 6, 5, 4, 2, 8, 2, 6, 1, 3, 8, 1, 0, 3, 3, 6, 3, 2, 7, 7, 0, 8, 0, 4, 8, 7, 2, 4, 8, 3, 0, 3, 2, 2, 1, 4, 1, 1, 3, 1, 1, 4, 3, 6, 2, 4, 5, 7, 8, 7, 1, 8, 4, 8, 2, 8, 1, 1, 2, 4, 0, 2, 2, 4, 6, 8, 3, 4, 2, 1, 6, 4, 7, 4, 1, 4, 1, 0, 8, 5, 6, 7, 4, 1, 4, 8, 4, 1, 4, 6, 5, 7, 0, 1, 4, 5, 8, 4, 1, 4, 0, 3, 4, 8, 2, 7, 8, 0, 6, 1, 1, 2, 1, 6, 8, 6, 8, 6, 7, 8, 1, 2, 1, 3, 1, 2, 4, 1, 1, 2, 4, 3, 7, 2, 7, 4, 6, 0, 8, 3, 6, 0, 0, 6, 8, 8, 0, 7, 1, 8, 5, 3, 5, 7, 2, 5, 3, 8, 1, 0, 6, 0, 6, 3, 7, 0, 8, 3, 5, 4, 8, 8, 5, 5, 1, 1, 7, 6, 7, 1, 2, 2, 1, 4, 8, 3, 3, 4, 0, 2, 0, 5, 6, 6, 6, 1, 5, 2, 3, 1, 0, 3, 3, 1, 4, 6, 4, 2, 7, 6, 5, 2, 3, 2, 3, 1, 5, 1, 6, 5, 5, 7, 7, 0, 3, 6, 5, 3, 4, 4, 8, 3, 2, 8, 2, 5, 2, 6, 3, 6, 0, 2, 0, 1, 6, 6, 6, 1, 7, 1, 2, 6, 8, 2, 5, 6, 5, 5, 7, 4, 3, 2, 2, 6, 5, 5, 4, 0, 5, 1, 6, 3, 3, 1, 8, 2, 8, 1, 3, 0, 3, 4, 6, 1, 7, 3, 2, 1, 1, 8, 3, 6, 8, 0, 8, 4, 8, 1, 5, 0, 1, 0, 1, 7, 5, 4, 5, 4, 4, 3, 6, 6, 3, 8, 7, 4, 0, 4, 2, 7, 7, 5, 3, 7, 7, 0, 6, 4, 1, 1, 7, 4, 0, 4, 5, 1, 2, 7, 8, 7, 0, 6, 5, 6, 0, 5, 5, 7, 7, 0, 8, 1, 5, 5, 5, 2, 8, 7, 6, 0, 6, 3, 4, 8, 5, 3, 4, 7, 7, 1, 7, 6, 0, 1, 2, 2, 1, 4, 3, 3, 0, 3, 4, 3, 1, 1, 7, 0, 3, 5, 1, 2, 7, 7, 3, 3, 4, 4, 1, 8, 6, 1, 5, 4, 0, 7, 7, 7, 3, 5, 8, 0, 5, 0, 3, 6, 2, 4, 1, 6, 0, 5, 2, 2, 4, 7, 3, 2, 2, 8, 5, 4, 1, 0, 5, 8, 8, 7, 8, 2, 3, 6, 1, 1, 5, 1, 5, 4, 3, 0, 6, 3, 5, 5, 0, 2, 5, 0, 7, 4, 4, 8, 4, 7, 2, 5, 6, 8, 2, 2, 2, 3, 1, 2, 7, 2, 3, 3, 4, 1, 1, 3, 1, 7, 4, 8, 8, 2, 6, 4, 4, 2, 4, 1, 7, 6, 3, 1, 2, 5, 0, 1, 0, 8, 5, 0, 0, 0, 6, 3, 3, 2, 8, 5, 3, 4, 3, 5, 1, 7, 0, 7, 6, 4, 6, 3, 2, 1, 6, 1, 7, 6, 5, 7, 1, 8, 1, 3, 2, 8, 2, 3, 6, 4, 5, 3, 7, 3, 3, 7, 0, 5, 1, 6, 6, 8, 2, 0, 0, 0, 1, 6, 5, 0, 0, 6, 3, 6, 1, 8, 5, 0, 6, 7, 3, 0, 5, 8, 1, 3, 8, 4, 0, 5, 4, 0, 1, 1, 4, 1, 2, 4, 3, 2, 1, 6, 8, 1, 8, 5, 4, 8, 5, 3, 1, 7, 7, 7, 3, 7, 0, 5, 3, 2, 4, 0, 2, 6, 1, 0, 5, 6, 7, 5, 6, 4, 8, 2, 3, 8, 0, 4, 1, 7, 4, 7, 1, 7, 8, 0, 1, 4, 6, 3, 7, 7, 7, 1, 3, 8, 6, 4, 8, 7, 5, 0, 1, 8, 1, 3, 1, 2, 7, 6, 4, 2, 0, 3, 5, 7, 5, 4, 5, 6, 8, 1, 3, 0, 7, 1, 0, 7, 7, 0, 5, 7, 6, 7, 3, 2, 4, 4, 4, 2, 2, 0, 5, 0, 0, 6, 1, 0, 2, 4, 7, 4, 2, 8, 3, 3, 5, 4, 2, 0, 1, 0, 8, 7, 1, 2, 3, 1, 0, 6, 4, 8, 4, 4, 7, 1, 0, 8, 8, 6, 7, 2, 6, 6, 5, 6, 3, 0, 3, 2, 4, 7, 6, 8, 4, 8, 4, 1, 1, 5, 2, 7, 3, 0, 4, 6, 0, 1, 4, 8, 4, 1, 7, 3, 1, 7, 7, 2, 2, 3, 0, 1, 4, 4, 6, 2, 2, 7, 4, 2, 7, 1, 5, 3, 3, 0, 1, 1, 4, 2, 1, 6, 0, 3, 2, 2, 3, 2, 1, 6, 7, 3, 2, 5, 1, 1, 8, 5, 6, 2, 3, 7, 7, 6, 8, 3, 7, 8, 2, 1, 6, 6, 0, 1, 1, 8, 4, 5, 8, 5, 5, 6, 6, 7, 3, 2, 6, 1, 6, 2, 2, 4, 4, 7, 5, 0, 8, 0, 4, 3, 2, 5, 0, 6, 1, 5, 7, 0, 0, 6, 8, 8, 8, 1, 2, 2, 1, 8, 4, 8, 1, 1, 2, 3, 1, 4, 1, 1, 1, 5, 3, 2, 5, 1, 1, 2, 5, 5, 8, 1, 6, 5, 1, 1, 0, 8, 5, 7, 6, 7, 3, 1, 2, 8, 8, 5, 7, 5, 8, 7, 2, 5, 7, 5, 3, 2, 4, 7, 2, 7, 8, 3, 0, 5, 8, 3, 5, 5, 4, 8, 3, 4, 8, 5, 7, 5, 1, 4, 7, 4, 5, 1, 6, 0, 2, 6, 7, 2, 4, 8, 1, 4, 4, 4, 8, 1, 2, 3, 1, 5, 6, 6, 0, 6, 4, 3, 5, 6, 8, 5, 3, 4, 8, 0, 2, 0, 3, 3, 8, 2, 1, 8, 2, 1, 7, 8, 4, 8, 6, 0, 3, 1, 1, 7, 3, 4, 6, 0, 7, 3, 4, 0, 3, 2, 7, 8, 3, 4, 4, 1, 7, 0, 2, 1, 2, 4, 5, 4, 7, 5, 6, 0, 4, 1, 3, 7, 6, 0, 2, 2, 4, 0, 0, 5, 3, 4, 7, 8, 7, 7, 8, 6, 5, 1, 3, 3, 7, 5, 4, 2, 0, 5, 5, 1, 7, 1, 0, 3, 1, 2, 6, 4, 0, 3, 8, 6, 4, 4, 0, 8, 4, 5, 1, 3, 6, 2, 2, 1, 0, 3, 6, 2, 4, 3, 4, 2, 5, 3, 2, 6, 4, 6, 3, 8, 7, 2, 2, 4, 3, 2, 3, 8, 2, 3, 1, 0, 5, 7, 6, 3, 6, 3, 5, 6, 3, 5, 3, 2, 7, 3, 7, 1, 5, 4, 3, 3, 3, 1, 7, 1, 4, 8, 5, 6, 2, 1, 4, 6, 5, 4, 3, 3, 3, 1, 3, 7, 5, 6, 1, 8, 6, 3, 8, 4, 6, 8, 3, 5, 7, 1, 0, 2, 0, 1, 1, 4, 3, 5, 5, 0, 6, 0, 3, 1, 8, 2, 5, 8, 1, 8, 6, 2, 8, 3, 5, 2, 3, 6, 2, 7, 0, 1, 6, 6, 7, 6, 2, 4, 0, 2, 3, 8, 1, 2, 6, 0, 0, 8, 3, 2, 5, 3, 8, 1, 4, 4, 1, 7, 1, 5, 6, 3, 6, 4, 1, 3, 0, 7, 5, 3, 4, 2, 4, 8, 6, 3, 1, 2, 2, 0, 2, 4, 5, 1, 4, 7, 1, 8, 7, 4, 8, 0, 8, 6, 2, 5, 7, 3, 8, 2, 7, 6, 7, 0, 5, 8, 0, 1, 7, 8, 3, 4, 2, 5, 5, 2, 8, 5, 2, 4, 3, 8, 7, 1, 3, 8, 3, 8, 8, 6, 0, 1, 7, 4, 8, 7, 6, 2, 4, 6, 4, 3, 4, 7, 4, 8, 2, 1, 1, 5, 3, 6, 6, 3, 6, 8, 3, 3, 4, 4, 0, 7, 0, 5, 6, 6, 0, 8, 0, 2, 5, 4, 5, 7, 2, 3, 2, 5, 6, 8, 6, 3, 6, 4, 2, 5, 4, 0, 4, 4, 4, 3, 6, 4, 6, 0, 7, 7, 7, 2, 8, 4, 0, 4, 7, 0, 2, 5, 4, 1, 0, 7, 8, 2, 3, 1, 1, 8, 7, 5, 5, 3, 4, 0, 3, 4, 5, 0, 8, 8, 5, 1, 0, 1, 2, 7, 1, 3, 8, 5, 4, 4, 1, 3, 7, 2, 0, 0, 3, 2, 5, 7, 1, 5, 8, 0, 0, 3, 0, 1, 6, 2, 1, 7, 4, 8, 6, 0, 0, 2, 1, 6, 8, 8, 0, 3, 1, 7, 7, 4, 8, 5, 4, 7, 0, 7, 6, 3, 1, 5, 1, 2, 5, 4, 7, 1, 5, 4, 3, 0, 7, 3, 7, 4, 6, 5, 0, 1, 0, 5, 5, 4, 3, 7, 1, 4, 6, 0, 7, 8, 5, 6, 5, 1, 4, 7, 5, 1, 7, 7, 3, 3, 1, 6, 8, 8, 1, 8, 3, 1, 6, 5, 2, 2]\n",
            "[1, 2, 5, 1, 4, 6, 5, 5, 7, 2, 4, 4, 6, 6, 4, 0, 1, 2, 3, 1, 6, 5, 5, 6, 2, 8, 0, 5, 2, 7, 0, 2, 5, 7, 4, 6, 8, 5, 4, 5, 8, 0, 5, 0, 4, 3, 8, 5, 1, 1, 3, 6, 7, 2, 3, 0, 7, 1, 3, 4, 7, 8, 5, 0, 6, 1, 5, 8, 2, 3, 2, 8, 2, 0, 1, 5, 0, 4, 3, 4, 7, 6, 0, 1, 0, 1, 4, 7, 2, 8, 2, 8, 2, 5, 6, 5, 4, 1, 6, 7, 7, 5, 1, 1, 8, 5, 0, 6, 4, 5, 7, 1, 6, 6, 7, 0, 4, 0, 5, 3, 1, 3, 6, 0, 2, 6, 0, 8, 2, 3, 1, 7, 7, 0, 5, 2, 2, 2, 0, 1, 2, 8, 3, 5, 0, 1, 7, 2, 4, 1, 3, 4, 0, 0, 6, 5, 8, 2, 8, 1, 5, 1, 8, 7, 8, 6, 2, 6, 8, 7, 0, 0, 6, 6, 1, 4, 0, 1, 3, 4, 8, 4, 6, 6, 8, 1, 7, 1, 2, 7, 8, 2, 8, 1, 8, 3, 2, 7, 3, 3, 6, 4, 4, 5, 3, 6, 3, 5, 5, 7, 2, 0, 6, 2, 6, 0, 4, 0, 0, 4, 6, 8, 5, 5, 2, 7, 1, 0, 1, 8, 1, 7, 3, 1, 5, 2, 8, 8, 2, 0, 8, 0, 8, 3, 0, 6, 8, 4, 4, 5, 3, 4, 4, 0, 5, 8, 3, 1, 1, 3, 2, 0, 4, 2, 6, 0, 2, 2, 4, 7, 8, 7, 3, 4, 8, 5, 0, 4, 5, 4, 2, 1, 1, 1, 3, 5, 8, 2, 4, 5, 0, 3, 0, 3, 3, 8, 2, 4, 1, 3, 1, 5, 3, 5, 2, 7, 3, 3, 2, 5, 0, 2, 1, 3, 0, 2, 8, 1, 2, 8, 0, 0, 3, 5, 5, 4, 8, 7, 0, 6, 7, 6, 0, 8, 5, 0, 2, 4, 7, 4, 8, 5, 6, 7, 5, 3, 0, 1, 4, 8, 1, 8, 8, 1, 6, 2, 2, 4, 7, 1, 8, 4, 5, 3, 5, 1, 2, 2, 1, 4, 3, 7, 3, 5, 1, 4, 4, 1, 5, 1, 0, 6, 5, 0, 4, 5, 3, 6, 0, 7, 8, 2, 7, 2, 0, 7, 8, 5, 3, 7, 7, 1, 8, 2, 1, 4, 1, 8, 2, 5, 7, 1, 7, 2, 7, 1, 7, 6, 6, 8, 3, 7, 7, 4, 4, 7, 0, 2, 2, 4, 6, 5, 8, 2, 1, 3, 0, 7, 1, 0, 8, 2, 4, 7, 6, 0, 7, 1, 6, 1, 3, 3, 7, 1, 5, 7, 8, 6, 5, 8, 3, 5, 4, 7, 2, 5, 2, 6, 2, 6, 4, 7, 1, 7, 3, 7, 1, 3, 7, 5, 0, 1, 2, 2, 5, 8, 0, 3, 3, 5, 8, 2, 1, 1, 7, 3, 4, 6, 0, 1, 5, 3, 6, 7, 4, 2, 7, 6, 1, 8, 3, 1, 4, 1, 5, 2, 8, 1, 4, 4, 5, 3, 6, 6, 5, 3, 6, 6, 5, 7, 0, 8, 2, 6, 7, 2, 8, 8, 4, 2, 1, 8, 5, 5, 0, 5, 6, 4, 5, 1, 7, 0, 6, 2, 7, 4, 2, 2, 0, 2, 5, 0, 4, 5, 5, 4, 6, 6, 1, 7, 5, 8, 0, 7, 5, 3, 2, 3, 3, 5, 2, 5, 4, 5, 4, 8, 8, 2, 0, 8, 7, 2, 4, 0, 2, 7, 7, 6, 2, 8, 8, 3, 7, 8, 8, 7, 5, 0, 8, 5, 2, 6, 0, 8, 4, 5, 4, 5, 2, 6, 1, 2, 8, 5, 4, 1, 7, 2, 6, 3, 7, 1, 1, 7, 6, 4, 3, 5, 2, 1, 7, 4, 6, 8, 1, 0, 0, 3, 0, 4, 5, 7, 8, 4, 6, 2, 0, 0, 8, 5, 8, 5, 4, 6, 4, 5, 6, 1, 6, 3, 1, 2, 1, 6, 2, 2, 3, 4, 5, 2, 7, 5, 0, 7, 4, 4, 3, 7, 6, 1, 2, 6, 7, 2, 8, 1, 4, 8, 4, 4, 4, 8, 3, 1, 2, 0, 2, 5, 1, 2, 4, 8, 0, 1, 4, 4, 7, 7, 6, 3, 3, 7, 5, 6, 0, 5, 1, 6, 5, 5, 3, 4, 6, 1, 0, 3, 3, 6, 4, 7, 1, 8, 8, 6, 4, 6, 5, 5, 1, 4, 3, 1, 8, 1, 0, 2, 0, 2, 2, 0, 5, 8, 3, 5, 5, 7, 1, 4, 8, 6, 5, 4, 6, 7, 0, 6, 0, 0, 2, 8, 7, 3, 5, 8, 6, 4, 3, 7, 0, 0, 8, 5, 8, 5, 2, 6, 8, 7, 3, 2, 0, 5, 1, 1, 7, 1, 6, 3, 8, 6, 6, 1, 3, 4, 7, 0, 1, 5, 5, 4, 8, 2, 3, 0, 2, 4, 7, 2, 7, 5, 3, 2, 5, 5, 8, 4, 7, 5, 6, 5, 2, 8, 7, 7, 0, 8, 5, 0, 4, 3, 2, 6, 3, 5, 1, 0, 6, 1, 2, 7, 0, 1, 0, 4, 4, 4, 2, 1, 6, 8, 7, 3, 4, 3, 0, 5, 1, 0, 3, 2, 5, 5, 6, 4, 1, 2, 4, 3, 3, 5, 8, 7, 7, 6, 4, 5, 7, 6, 3, 1, 4, 7, 3, 1, 5, 0, 1, 5, 7, 1, 0, 3, 3, 4, 5, 2, 2, 8, 1, 0, 1, 3, 4, 8, 5, 3, 7, 4, 6, 2, 0, 8, 3, 4, 8, 4, 8, 2, 5, 2, 7, 3, 3, 6, 0, 3, 1, 2, 4, 7, 6, 2, 1, 4, 5, 7, 5, 5, 5, 6, 0, 8, 4, 0, 5, 4, 7, 7, 8, 2, 4, 4, 4, 2, 1, 6, 6, 1, 3, 4, 8, 8, 1, 1, 0, 4, 8, 7, 8, 3, 3, 0, 7, 1, 2, 4, 0, 6, 7, 1, 6, 8, 2, 1, 0, 8, 7, 1, 0, 3, 1, 5, 6, 0, 6, 4, 0, 5, 6, 1, 8, 8, 5, 3, 6, 3, 0, 4, 7, 6, 0, 5, 7, 1, 0, 1, 6, 6, 7, 5, 3, 5, 1, 6, 3, 4, 5, 3, 5, 2, 3, 7, 1, 8, 8, 0, 5, 0, 0, 7, 6, 8, 4, 6, 7, 8, 7, 2, 5, 5, 5, 8, 6, 1, 4, 1, 0, 7, 2, 0, 4, 4, 0, 8, 1, 0, 0, 1, 5, 3, 1, 8, 2, 8, 5, 8, 5, 1, 7, 0, 7, 1, 0, 1, 0, 7, 2, 6, 8, 3, 5, 5, 2, 0, 8, 1, 2, 2, 8, 7, 0, 5, 6, 8, 2, 1, 4, 7, 0, 4, 4, 8, 0, 6, 0, 2, 7, 7, 8, 6, 6, 8, 6, 2, 1, 0, 2, 7, 4, 8, 0, 0, 3, 0, 0, 5, 1, 4, 0, 3, 8, 8, 2, 1, 3, 0, 6, 6, 7, 2, 1, 2, 7, 2, 7, 4, 6, 0, 5, 8, 3, 7, 7, 2, 7, 1, 3, 2, 1, 4, 6, 7, 0, 7, 2, 7, 4, 2, 0, 0, 3, 6, 1, 0, 3, 8, 1, 1, 2, 3, 1, 0, 5, 1, 4, 3, 2, 7, 8, 1, 6, 1, 7, 6, 1, 0, 5, 6, 6, 2, 3, 4, 3, 4, 1, 4, 6, 4, 6, 1, 1, 8, 6, 0, 3, 3, 6, 1, 3, 3, 0, 3, 0, 1, 6, 8, 1, 4, 6, 8, 7, 6, 4, 4, 1, 6, 1, 0, 1, 4, 6, 8, 3, 8, 3, 5, 1, 7, 3, 1, 5, 4, 2, 1, 6, 4, 8, 5, 5, 3, 2, 8, 2, 5, 4, 4, 1, 5, 3, 4, 6, 5, 2, 7, 1, 4, 6, 6, 3, 0, 2, 8, 4, 5, 5, 2, 5, 2, 7, 1, 5, 4, 6, 1, 2, 5, 1, 1, 2, 3, 8, 5, 4, 5, 6, 6, 0, 3, 6, 3, 3, 2, 2, 4, 2, 8, 1, 7, 3, 3, 1, 5, 8, 8, 2, 7, 7, 6, 8, 8, 4, 6, 1, 5, 3, 6, 6, 2, 0, 6, 3, 4, 4, 7, 5, 1, 6, 4, 6, 5, 8, 1, 2, 6, 6, 4, 4, 2, 8, 2, 5, 0, 8, 4, 2, 6, 4, 8, 7, 0, 5, 7, 4, 5, 8, 0, 6, 3, 3, 1, 1, 6, 7, 0, 2, 5, 2, 6, 4, 4, 1, 4, 7, 5, 3, 1, 4, 4, 7, 4, 8, 3, 4, 5, 7, 6, 7, 7, 5, 4, 3, 3, 1, 7, 3, 0, 8, 8, 5, 5, 0, 3, 4, 7, 8, 5, 6, 8, 0, 1, 8, 8, 2, 6, 0, 0, 4, 1, 4, 5, 7, 3, 1, 0, 2, 5, 2, 2, 8, 8, 6, 0, 2, 1, 7, 3, 1, 8, 3, 5, 5, 5, 8, 8, 4, 3, 1, 5, 8, 4, 7, 3, 8, 7, 6, 8, 8, 6, 1, 6, 6, 0, 5, 7, 1, 0, 1, 1, 0, 6, 7, 3, 5, 6, 6, 6, 0, 0, 8, 8, 0, 2, 7, 5, 6, 0, 2, 1, 1, 3, 1, 0, 8, 2, 8, 7, 6, 4, 2, 2, 1, 5, 3, 8, 8, 2, 4, 5, 7, 3, 1, 4, 0, 3, 5, 4, 5, 3, 2, 3, 7, 0, 6, 4, 4, 8, 0, 5, 8, 2, 2, 3, 5, 5, 0, 3, 2, 5, 8, 0, 4, 8, 2, 4, 8, 2, 6, 8, 0, 1, 1, 6, 4, 8, 3, 5, 1, 5, 3, 3, 8, 8, 7, 4, 2, 4, 7, 6, 7, 7, 1, 0, 3, 5, 5, 6, 1, 5, 1, 5, 6, 7, 2, 3, 5, 5, 4, 6, 0, 5, 5, 7, 2, 2, 8, 0, 7, 8, 7, 7, 7, 0, 6, 8, 3, 0, 1, 0, 0, 8, 7, 2, 0, 1, 3, 0, 7, 5, 2, 8, 6, 1, 2, 0, 7, 8, 3, 3, 1, 6, 5, 8, 7, 0, 6, 0, 3, 3, 7, 1, 4, 5, 7, 1, 2, 1, 4, 6, 6, 4, 6, 5, 4, 1, 0, 7, 2, 1, 8, 4, 5, 3, 5, 4, 1, 2, 1, 7, 2, 5, 2, 4, 5, 5, 3, 0, 7, 1, 0, 6, 4, 0, 3, 0, 3, 6, 8, 1, 4, 3, 0, 1, 7, 6, 1, 2, 6, 2, 2, 3, 2, 4, 4, 5, 6, 1, 8, 5, 0, 5, 3, 0, 1, 7, 7, 7, 6, 0, 4, 2, 0, 4, 1, 7, 4, 7, 3, 4, 3, 6, 4, 5, 5, 2, 4, 0, 6, 1, 1, 3, 7, 2, 2, 1, 2, 8, 4, 5, 6, 3, 0, 6, 1, 3, 5, 3, 4, 6, 1, 4, 2, 5, 3, 5, 5, 0, 0, 1, 4, 1, 6, 0, 7, 3, 6, 1, 5, 7, 6, 6, 8, 5, 7, 7, 2, 3, 1, 0, 3, 3, 8, 7, 0, 3, 4, 3, 7, 4, 7, 3, 8, 5, 2, 4, 8, 2, 8, 0, 1, 1, 2, 4, 0, 5, 3, 8, 1, 8, 5, 4, 6, 6, 4, 7, 6, 7, 3, 4, 6, 7, 1, 1, 7, 4, 3, 8, 7, 1, 0, 1, 3, 0, 7, 8, 0, 0, 7, 8, 7, 4, 0, 8, 3, 0, 2, 5, 5, 5, 5, 7, 7, 6, 3, 0, 6, 2, 0, 0, 8, 7, 6, 7, 6, 6, 5, 2, 4, 0, 8, 6, 2, 7, 1, 3, 0, 1, 7, 1, 1, 3, 2, 3, 6, 0, 5, 1, 2, 0, 6, 3, 4, 5, 2, 8, 8, 0, 6, 4, 1, 7, 6, 7, 0, 2, 4, 7, 0, 6, 5, 8, 3, 5, 4, 8, 2, 4, 7, 1, 4, 3, 7, 5, 7, 2, 7, 3, 1, 0, 3, 1, 2, 6, 3, 5, 1, 2, 5, 8, 8, 6, 2, 2, 7, 5, 2, 5, 8, 2, 1, 1, 7, 3, 8, 3, 0, 3, 4, 5, 1, 1, 7, 3, 1, 2, 7, 4, 7, 1, 8, 5, 7, 6, 4, 1, 5, 8, 1, 4, 5, 6, 7, 8, 0, 3, 6, 0, 0, 1, 7, 3, 4, 5, 7, 7, 3, 1, 3, 3, 3, 0, 2, 3, 2, 8, 2, 2, 6, 6, 3, 2, 5, 4, 3, 0, 1, 7, 1, 2, 4, 5, 3, 2, 6, 2, 2, 0, 2, 8, 5, 0, 8, 8, 4, 5, 1, 7, 3, 8, 5, 2, 1, 1, 0, 1, 5, 8, 3, 8, 1, 1, 3, 1, 6, 8, 5, 5, 6, 0, 6, 3, 0, 1, 8, 3, 5, 2, 6, 7, 4, 3, 5, 3, 4, 6, 2, 4, 3, 7, 4, 7, 7, 0, 8, 4, 6, 5, 7, 0, 1, 3, 6, 0, 3, 3, 3, 3, 3, 7, 7, 4, 8, 5, 3, 5, 4, 8, 7, 8, 8, 4, 6, 4, 3, 3, 4, 8, 1, 7, 3, 8, 2, 6, 8, 1, 5, 8, 1, 0, 7, 0, 8, 5, 8, 6, 6, 2, 6, 0, 0, 5, 4, 7, 6, 7, 0, 0, 4, 4, 2, 6, 6, 2, 7, 0, 6, 5, 8, 2, 5, 5, 1, 3, 5, 1, 0, 4, 6, 6, 2, 1, 2, 0, 4, 8, 6, 5, 5, 7, 3, 0, 1, 1, 4, 0, 5, 7, 1, 4, 2, 5, 1, 6, 8, 3, 5, 8, 2, 1, 1, 7, 6, 7, 6, 6, 1, 8, 2, 4, 1, 3, 7, 0, 4, 3, 2, 6, 6, 7, 5, 0, 8, 0, 7, 3, 4, 6, 1, 3, 2, 4, 4, 0, 8, 3, 2, 7, 0, 7, 5, 2, 8, 7, 5, 0, 8, 6, 4, 3, 7, 4, 3, 8, 8, 1, 6, 7, 7, 0, 3, 8, 0, 6, 1, 4, 7, 0, 1, 8, 5, 4, 6, 5, 5, 6, 0, 1, 5, 6, 6, 0, 5, 7, 7, 0, 4, 2, 2, 0, 8, 2, 8, 4, 1, 6, 7, 4, 2, 1, 1, 0, 4, 0, 3, 6, 1, 0, 2, 1, 3, 4, 2, 0, 2, 7, 7, 4, 6, 2, 3, 5, 0, 0, 4, 4, 6, 8, 3, 8, 7, 2, 2, 1, 3, 7, 1, 0, 6, 2, 7, 3, 7, 8, 2, 2, 8, 3, 4, 8, 2, 1, 2, 5, 6, 4, 7, 1, 0, 8, 6, 2, 3, 1, 2, 8, 1, 7, 8, 3, 5, 7, 5, 4, 3, 6, 3, 5, 6, 7, 4, 8, 8, 4, 7, 6, 8, 8, 5, 1, 7, 3, 3, 5, 2, 5, 0, 7, 3, 7, 7, 8, 3, 1, 7, 2, 1, 8, 7, 5, 4, 6, 1, 4, 0, 2, 5, 5, 6, 6, 1, 6, 4, 6, 8, 3, 4, 5, 2, 8, 4, 2, 8, 2, 7, 6, 6, 5, 2, 5, 8, 2, 2, 6, 3, 1, 2, 0, 7, 6, 2, 3, 4, 7, 4, 5, 0, 5, 4, 1, 6, 1, 8, 5, 5, 1, 6, 0, 8, 2, 0, 7, 7, 0, 5, 2, 0, 6, 3, 6, 4, 0, 2, 1, 8, 7, 4, 7, 4, 2, 4, 2, 3, 5, 3, 5, 7, 7, 8, 1, 4, 0, 4, 3, 6, 5, 7, 3, 3, 8, 7, 2, 3, 0, 8, 8, 4, 6, 3, 8, 7, 0, 3, 6, 7, 3, 4, 4, 7, 0, 0, 8, 6, 2, 0, 3, 6, 2, 1, 2, 8, 1, 2, 7, 6, 7, 8, 2, 8, 3, 1, 2, 3, 1, 2, 8, 7, 4, 3, 7, 5, 6, 1, 2, 3, 1, 2, 8, 2, 8, 0, 3, 3, 7, 3, 7, 8, 1, 0, 8, 3, 5, 8, 2, 7, 0, 4, 8, 1, 1, 5, 4, 1, 2, 3, 7, 0, 8, 6, 4, 4, 5, 4, 2, 2, 2, 5, 5, 4, 0, 6, 7, 0, 0, 2, 4, 8, 0, 3, 1, 0, 0, 0, 0, 0, 7, 6, 8, 5, 4, 3, 7, 7, 4, 7, 2, 6, 7, 0, 3, 4, 4, 6, 4, 4, 7, 1, 2, 2, 8, 6, 2, 8, 8, 5, 8, 1, 5, 7, 0, 8, 6, 7, 5, 8, 2, 0, 4, 0, 5, 5, 6, 8, 2, 0, 4, 0, 0, 3, 2, 2, 2, 3, 8, 7, 4, 4, 8, 4, 7, 0, 4, 2, 8, 4, 0, 3, 2, 2, 5, 3, 7, 0, 7, 8, 5, 3, 3, 7, 6, 0, 3, 4, 3, 5, 6, 6, 2, 6, 3, 0, 0, 1, 0, 6, 1, 6, 7, 1, 7, 8, 1, 8, 6, 2, 2, 8, 1, 6, 6, 8, 0, 1, 5, 6, 5, 8, 3, 8, 8, 6, 8, 0, 7, 6, 3, 8, 6, 3, 2, 0, 6, 6, 0, 7, 7, 3, 4, 4, 3, 3, 6, 0, 1, 8, 8, 7, 0, 7, 4, 6, 8, 8, 4, 6, 2, 4, 7, 7, 6, 0, 2, 7, 2, 2, 7, 0, 3, 7, 1, 7, 0, 3, 1, 8, 6, 4, 1, 2, 6, 7, 4, 5, 8, 4, 7, 5, 1, 2, 5, 8, 4, 6, 5, 5, 2, 3, 2, 5, 1, 5, 3, 5, 2, 2, 3, 0, 7, 7, 1, 7, 2, 4, 3, 7, 4, 1, 5, 7, 5, 6, 4, 5, 7, 2, 2, 1, 6, 6, 7, 1, 4, 1, 0, 6, 2, 6, 2, 8, 5, 7, 3, 5, 7, 4, 3, 7, 8, 4, 6, 2, 3, 0, 8, 1, 0, 1, 6, 4, 0, 5, 2, 8, 3, 2, 8, 1, 0, 7, 0, 0, 1, 4, 3, 1, 5, 2, 6, 0, 0, 8, 3, 7, 6, 3, 2, 4, 5, 3, 8, 0, 7, 6, 6, 8, 8, 3, 6, 0, 3, 1, 2, 4, 1, 5, 2, 6, 2, 3, 8, 5, 8, 0, 3, 7, 8, 0, 8, 2, 0, 3, 4, 7, 4, 1, 3, 7, 2, 3, 3, 4, 1, 8, 7, 2, 7, 0, 5, 2, 2, 5, 2, 2, 2, 8, 0, 1, 8, 4, 5, 6, 2, 0, 4, 7, 0, 6, 5, 8, 7, 6, 0, 0, 6, 6, 5, 7, 7, 8, 6, 8, 4, 4, 6, 1, 7, 4, 8, 5, 7, 6, 0, 2, 0, 3, 0, 8, 7, 2, 3, 7, 4, 2, 4, 4, 3, 1, 8, 7, 1, 3, 5, 7, 7, 4, 0, 5, 0, 4, 1, 6, 2, 4, 3, 1, 7, 0, 0, 7, 7, 6, 3, 7, 0, 2, 5, 7, 3, 0, 8, 3, 7, 4, 3, 1, 3, 8, 2, 7, 3, 5, 2, 4, 4, 8, 7, 3, 7, 5, 8, 2, 7, 4, 5, 5, 1, 2, 7, 4, 2, 0, 7, 3, 3, 1, 5, 6, 3, 7, 0, 2, 5, 6, 8, 0, 4, 5, 0, 8, 7, 3, 4, 8, 1, 0, 7, 0, 6, 2, 1, 7, 5, 7, 4, 4, 8, 3, 4, 6, 4, 5, 4, 5, 6, 3, 7, 2, 5, 0, 8, 2, 6, 4, 7, 3, 4, 4, 4, 3, 5, 6, 6, 7, 1, 8, 6, 5, 3, 3, 0, 4, 2, 4, 8, 4, 4, 2, 8, 3, 7, 2, 1, 1, 4, 0, 7, 1, 8, 2, 7, 6, 3, 4, 1, 8, 1, 8, 8, 8, 3, 2, 8, 2, 1, 2, 5, 3, 1, 2, 6, 0, 8, 5, 2, 6, 3, 4, 5, 8, 3, 5, 7, 6, 5, 6, 5, 4, 1, 4, 7, 8, 1, 8, 3, 6, 2, 3, 3, 5, 7, 0, 0, 4, 1, 1, 7, 7, 0, 2, 3, 3, 7, 1, 1, 3, 4, 0, 0, 5, 0, 5, 5, 1, 3, 7, 0, 8, 0, 5, 3, 0, 5, 6, 1, 4, 2, 7, 4, 7, 2, 3, 1, 5, 2, 6, 8, 5, 6, 2, 6, 7, 4, 6, 6, 0, 6, 7, 0, 7, 5, 8, 1, 6, 5, 1, 8, 7, 3, 6, 1, 8, 5, 1, 7, 6, 4, 4, 6, 4, 8, 6, 6, 3, 3, 7, 2, 7, 5, 8, 2, 2, 2, 3, 4, 8, 4, 2, 7, 8, 6, 5, 7, 3, 3, 6, 1, 3, 2, 7, 4, 3, 1, 1, 7, 7, 8, 7, 1, 4, 5, 0, 0, 3, 2, 1, 0, 0, 4, 5, 4, 3, 5, 6, 8, 0, 1, 7, 7, 6, 6, 1, 6, 3, 3, 2, 5, 6, 5, 1, 7, 0, 2, 7, 8, 3, 7, 2, 5, 2, 6, 0, 1, 5, 8, 6, 3, 7, 6, 4, 7, 2, 1, 6, 0, 2, 8, 1, 1, 4, 2, 0, 5, 5, 2, 5, 2, 4, 2, 4, 8, 4, 1, 6, 3, 4, 5, 6, 1, 0, 1, 1, 5, 1, 3, 4, 0, 2, 7, 6, 8, 3, 7, 3, 6, 2, 1, 2, 0, 8, 7, 5, 6, 0, 6, 8, 3, 8, 4, 6, 4, 5, 2, 0, 6, 3, 8, 4, 0, 5, 0, 3, 1, 2, 1, 1, 8, 2, 4, 7, 3, 5, 1, 5, 4, 8, 5, 3, 0, 4, 8, 6, 2, 3, 3, 5, 8, 1, 6, 4, 2, 6, 8, 1, 8, 3, 1, 7, 0, 6, 6, 4, 1, 0, 1, 2, 8, 5, 6, 3, 6, 4, 2, 7, 3, 8, 4, 6, 5, 7, 5, 4, 1, 7, 4, 0, 8, 2, 2, 3, 3, 3, 8, 1, 1, 4, 2, 1, 2, 8, 4, 8, 1, 1, 8, 0, 4, 0, 5, 1, 2, 0, 6, 1, 8, 2, 5, 3, 6, 3, 4, 0, 0, 7, 6, 0, 5, 0, 8, 3, 7, 2, 0, 7, 2, 0, 6, 6, 1, 4, 3, 8, 4, 7, 0, 2, 8, 1, 8, 5, 3, 5, 8, 6, 7, 1, 4, 5, 6, 2, 5, 6, 6, 8, 0, 3, 2, 8, 4, 7, 6, 7, 2, 5, 3, 8, 5, 8, 8, 4, 5, 8, 0, 2, 3, 1, 0, 7, 6, 4, 7, 1, 8, 8, 1, 0, 2, 0, 3, 4, 0, 3, 1, 7, 6, 6, 0, 3, 6, 0, 4, 2, 6, 0, 4, 8, 7, 5, 1, 7, 7, 1, 0, 3, 3, 7, 8, 1, 7, 2, 5, 8, 5, 5, 2, 5, 8, 1, 6, 6, 2, 8, 1, 6, 0, 5, 7, 8, 1, 2, 4, 5, 4, 3, 8, 4, 8, 5, 4, 6, 3, 2, 3, 7, 1, 1, 5, 8, 3, 5, 2, 2, 8, 8, 1, 6, 2, 0, 6, 4, 5, 8, 8, 3, 1, 7, 6, 6, 6, 8, 4, 4, 6, 1, 0, 0, 4, 0, 3, 8, 0, 3, 8, 5, 7, 4, 3, 2, 8, 1, 2, 8, 7, 2, 8, 1, 8, 7, 8, 1, 3, 7, 1, 3, 6, 2, 1, 7, 5, 7, 8, 4, 6, 5, 1, 4, 5, 3, 7, 8, 3, 0, 1, 6, 4, 8, 0, 2, 4, 5, 3, 8, 1, 1, 4, 6, 0, 2, 2, 7, 2, 6, 4, 0, 8, 2, 7, 5, 7, 2, 2, 8, 0, 7, 4, 3, 8, 0, 2, 5, 8, 8, 8, 4, 0, 6, 3, 7, 4, 0, 2, 7, 0, 6, 6, 7, 2, 4, 2, 3, 6, 6, 6, 8, 0, 3, 1, 1, 4, 7, 3, 6, 3, 6, 7, 0, 1, 2, 3, 7, 2, 6, 8, 3, 4, 1, 7, 2, 1, 2, 7, 2, 6, 5, 7, 0, 0, 6, 6, 7, 2, 5, 6, 8, 1, 6, 6, 6, 5, 7, 8, 5, 8, 6, 1, 8, 0, 5, 2, 2, 8, 2, 0, 3, 3, 5, 5, 4, 3, 3, 5, 6, 4, 7, 2, 7, 0, 0, 5, 3, 7, 7, 8, 0, 4, 0, 4, 2, 1, 8, 6, 3, 5, 7, 5, 0, 7, 7, 3, 1, 4, 8, 3, 5, 1, 3, 7, 4, 3, 8, 6, 5, 3, 3, 5, 5, 4, 5, 0, 4, 0, 5, 6, 4, 2, 7, 6, 3, 8, 2, 8, 7, 5, 0, 8, 5, 8, 4, 2, 6, 5, 0, 4, 7, 3, 2, 5, 3, 6, 6, 0, 0, 2, 8, 0, 5, 0, 7, 4, 6, 8, 8, 6, 5, 8, 3, 4, 8, 3, 8, 6, 4, 4, 0, 0, 8, 8, 1, 7, 4, 3, 5, 7, 7, 2, 6, 5, 8, 5, 6, 0, 2, 4, 0, 2, 4, 1, 2, 4, 5, 3, 2, 3, 3, 1, 2, 1, 6, 7, 5, 2, 3, 6, 5, 0, 1, 7, 0, 8, 7, 4, 5, 1, 6, 3, 2, 7, 2, 1, 3, 2, 0, 6, 1, 2, 6, 4, 3, 2, 2, 4, 1, 5, 1, 4, 6, 0, 0, 7, 1, 1, 5, 3, 4, 7, 5, 3, 8, 1, 8, 8, 1, 7, 8, 7, 0, 1, 4, 1, 5, 5, 5, 0, 5, 7, 8, 5, 3, 7, 8, 5, 5, 1, 1, 4, 1, 1, 0, 1, 7, 1, 6, 1, 5, 7, 3, 7, 0, 3, 0, 8, 3, 2, 7, 0, 7, 6, 8, 2, 7, 0, 1, 5, 5, 0, 5, 7, 7, 8, 1, 0, 2, 5, 8, 8, 0, 6, 1, 7, 0, 0, 6, 8, 3, 3, 8, 0, 5, 8, 8, 5, 3, 2, 5, 5, 8, 4, 4, 4, 5, 7, 4, 2, 2, 2, 0, 3, 8, 6, 5, 1, 0, 3, 5, 4, 6, 5, 8, 0, 0, 6, 8, 7, 8, 1, 5, 0, 6, 2, 3, 7, 3, 5, 3, 1, 0, 3, 4, 7, 8, 6, 3, 8, 4, 6, 1, 2, 0, 2, 2, 1, 5, 3, 0, 0, 3, 6, 2, 1, 7, 5, 6, 1, 3, 6, 6, 3, 8, 7, 8, 6, 5, 1, 2, 0, 1, 6, 3, 0, 4, 4, 5, 1, 8, 3, 2, 5, 7, 1, 3, 3, 5, 0, 8, 0, 8, 2, 7, 4, 7, 3, 4, 6, 1, 0, 5, 5, 4, 8, 8, 0, 6, 3, 3, 6, 5, 0, 5, 8, 4, 4, 3, 6, 5, 0, 2, 6, 8, 6, 2, 4, 5, 5, 4, 0, 0, 3, 1, 5, 0, 1, 7, 4, 1, 0, 0, 8, 2, 3, 0, 5, 8, 7, 0, 5, 3, 6, 4, 7, 5, 3, 6, 8, 5, 3, 8, 0, 8, 2, 7, 3, 5, 7, 8, 1, 4, 3, 1, 5, 3, 4, 2, 7, 7, 5, 8, 8, 0, 3, 7, 0, 0, 4, 6, 5, 8, 8, 5, 1, 5, 6, 8, 3, 0, 1, 1, 8, 6, 1, 8, 4, 4, 4, 0, 4, 1, 4, 7, 2, 5, 7, 2, 3, 7, 2, 0, 6, 6, 0, 4, 4, 8, 0, 1, 5, 2, 5, 1, 5, 8, 4, 2, 7, 1, 3, 5, 6, 1, 4, 4, 3, 5, 8, 4, 1, 7, 2, 7, 1, 0, 5, 5, 1, 3, 6, 5, 7, 4, 0, 6, 3, 2, 5, 4, 0, 2, 2, 3, 4, 3, 7, 1, 8, 3, 2, 4, 1, 8, 3, 4, 2, 1, 4, 2, 8, 8, 1, 0, 8, 0, 3, 6, 8, 3, 3, 2, 3, 5, 6, 2, 1, 1, 4, 2, 0, 5, 7, 8, 4, 1, 8, 0, 3, 6, 5, 5, 3, 0, 1, 2, 2, 7, 7, 0, 8, 1, 4, 6, 0, 3, 4, 2, 0, 2, 0, 2, 3, 8, 7, 4, 5, 0, 6, 8, 6, 1, 8, 5, 8, 6, 8, 6, 8, 6, 5, 0, 7, 5, 2, 3, 4, 4, 1, 8, 7, 0, 3, 3, 4, 8, 0, 0, 6, 7, 2, 3, 8, 5, 0, 5, 0, 6, 0, 5, 1, 2, 8, 3, 6, 3, 6, 8, 6, 4, 6, 6, 5, 6, 4, 6, 1, 2, 3, 7, 2, 6, 4, 8, 3, 8, 8, 5, 3, 5, 4, 4, 6, 1, 0, 8, 7, 8, 0, 7, 8, 5, 6, 6, 0, 3, 0, 5, 8, 8, 3, 0, 4, 6, 4, 1, 2, 2, 2, 3, 3, 0, 1, 1, 1, 3, 1, 2, 4, 7, 1, 5, 6, 4, 3, 6, 3, 0, 5, 0, 6, 4, 3, 0, 7, 4, 2, 0, 6, 4, 0, 5, 6, 2, 5, 4, 1, 4, 1, 5, 5, 8, 7, 6, 1, 0, 7, 6, 1, 6, 8, 1, 5, 8, 5, 8, 3, 4, 3, 0, 1, 8, 5, 3, 6, 7, 2, 3, 8, 0, 7, 5, 2, 4, 8, 7, 7, 7, 6, 5, 4, 8, 3, 8, 5, 8, 4, 8, 2, 7, 2, 7, 4, 6, 6, 8, 1, 4, 8, 4, 2, 6, 5, 1, 0, 0, 7, 6, 4, 7, 1, 2, 0, 4, 0, 3, 5, 2, 6, 5, 3, 8, 0, 1, 4, 8, 5, 0, 1, 7, 8, 0, 0, 6, 7, 3, 3, 4, 6, 0, 8, 7, 2, 3, 0, 4, 8, 5, 7, 7, 7, 2, 0, 1, 8, 3, 0, 4, 1, 1, 3, 3, 0, 7, 4, 2, 6, 4, 7, 7, 4, 1, 0, 2, 8, 0, 6, 7, 2, 8, 7, 0, 0, 7, 2, 3, 7, 2, 7, 7, 3, 6, 3, 8, 6, 1, 7, 1, 5, 3, 6, 2, 8, 0, 8, 1, 6, 5, 8, 1, 0, 5, 2, 6, 1, 2, 4, 4, 2, 8, 7, 0, 1, 5, 1, 7, 6, 8, 1, 1, 7, 1, 3, 7, 1, 3, 5, 4, 0, 8, 5, 8, 8, 3, 3, 5, 8, 0, 2, 8, 5, 2, 5, 0, 7, 6, 5, 8, 1, 0, 5, 5, 8, 6, 8, 2, 5, 4, 4, 7, 5, 3, 0, 0, 1, 3, 2, 5, 0, 4, 0, 3, 3, 7, 4, 0, 3, 5, 6, 1, 0, 7, 7, 5, 3, 3, 5, 2, 4, 8, 7, 2, 6, 0, 3, 0, 5, 8, 2, 7, 0, 7, 6, 6, 4, 1, 6, 8, 3, 5, 0, 5, 1, 3, 0, 0, 2, 5, 3, 1, 4, 4, 6, 6, 6, 0, 2, 5, 3, 6, 7, 6, 1, 4, 2, 7, 3, 2, 4, 6, 6, 5, 8, 4, 1, 0, 7, 4, 5, 5, 5, 3, 3, 7, 6, 8, 5, 3, 6, 5, 4, 4, 0, 0, 8, 2, 3, 7, 4, 7, 1, 2, 3, 0, 5, 5, 8, 6, 5, 6, 8, 6, 2, 5, 5, 3, 7, 4, 5, 6, 3, 1, 7, 0, 1, 5, 3, 1, 5, 7, 0, 7, 8, 6, 1, 7, 1, 1, 5, 1, 5, 1, 8, 7, 6, 0, 8, 3, 3, 1, 8, 8, 6, 7, 7, 3, 7, 2, 6, 0, 5, 6, 6, 5, 5, 2, 2, 5, 8, 3, 8, 1, 3, 7, 6, 7, 4, 5, 7, 2, 3, 7, 1, 6, 2, 5, 2, 7, 6, 1, 0, 6, 3, 6, 5, 4, 6, 3, 4, 0, 8, 1, 2, 5, 2, 3, 0, 3, 3, 6, 4, 1, 0, 0, 7, 8, 1, 2, 4, 6, 0, 0, 8, 3, 2, 1, 3, 6, 7, 7, 8, 5, 7, 7, 8, 4, 8, 0, 6, 2, 0, 5, 0, 7, 6, 3, 0, 2, 2, 3, 6, 7, 2, 1, 7, 1, 2, 4, 5, 7, 3, 4, 8, 6, 8, 8, 0, 5, 7, 3, 3, 1, 0, 6, 6, 8, 7, 4, 3, 5, 4, 6, 3, 7, 3, 8, 0, 3, 6, 2, 0, 0, 7, 6, 4, 5, 6, 4, 8, 5, 8, 7, 5, 5, 7, 2, 6, 4, 2, 0, 2, 5, 2, 3, 7, 5, 3, 8, 7, 7, 5, 8, 6, 8, 0, 4, 4, 5, 1, 0, 4, 0, 0, 2, 4, 2, 8, 0, 7, 7, 2, 0, 8, 2, 3, 1, 2, 3, 3, 8, 0, 4, 3, 8, 0, 6, 2, 4, 4, 6, 3, 0, 1, 4, 8, 1, 4, 7, 3, 5, 4, 4, 2, 7, 3, 7, 6, 0, 1, 4, 3, 7, 2, 7, 0, 4, 3, 1, 3, 5, 8, 8, 4, 1, 7, 3, 5, 0, 2, 6, 1, 5, 2, 1, 8, 1, 0, 1, 0, 0, 3, 3, 0, 0, 4, 5, 4, 2, 5, 2, 6, 0, 5, 2, 1, 1, 3, 5, 5, 2, 4, 5, 1, 2, 1, 2, 4, 8, 2, 4, 4, 6, 0, 7, 6, 7, 2, 7, 7, 5, 3, 4, 2, 7, 7, 2, 5, 2, 6, 8, 4, 3, 5, 2, 4, 5, 0, 0, 0, 6, 6, 0, 7, 5, 0, 5, 3, 7, 2, 1, 4, 3, 8, 3, 2, 3, 5, 7, 1, 2, 8, 0, 7, 1, 6, 0, 8, 7, 6, 5, 7, 7, 8, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 초기화\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/graphcodebert-base\", num_labels=9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTGq-6QmfpyI",
        "outputId": "aca5a6f3-e651-44a0-d8fb-d17a6fc361e3"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 옵티마이저 및 스케줄러 설정\n",
        "learning_rate = 2e-5\n",
        "def create_optimizer_and_scheduler(self, num_training_steps):\n",
        "    self.optimizer = torch.optim.AdamW(\n",
        "        self.model.parameters(),\n",
        "        lr=learning_rate,\n",
        "        betas=(0.9, 0.99),\n",
        "        eps=1e-8,\n",
        "        weight_decay=0.1\n",
        "    )\n",
        "    self.lr_scheduler = get_cosine_schedule_with_warmup(\n",
        "        self.optimizer,\n",
        "        num_warmup_steps=5,\n",
        "        num_training_steps=num_training_steps\n",
        "    )\n",
        "    return self.optimizer, self.lr_scheduler\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "7elagmYkZ1Qx"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 메트릭 계산 함수 정의\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    f1_per_class = f1_score(labels, predictions, average=None)\n",
        "    f1_weighted = f1_score(labels, predictions, average='weighted')\n",
        "    f1_macro = f1_score(labels, predictions, average='macro')\n",
        "    f1_micro = f1_score(labels, predictions, average='micro')\n",
        "    recall_weighted = recall_score(labels, predictions, average='weighted')\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "\n",
        "    metrics = {\n",
        "        'accuracy': accuracy,\n",
        "        'recall_weighted': recall_weighted,\n",
        "        'f1_weighted': f1_weighted,\n",
        "        'f1_macro': f1_macro,\n",
        "        'f1_micro': f1_micro,\n",
        "    }\n",
        "\n",
        "    for i, f1 in enumerate(f1_per_class):\n",
        "        metrics[f'f1_class_{i}'] = f1\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "hPijsFJOZ1Me"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용자 정의 콜백 클래스 정의\n",
        "class CustomTrainerCallback(TrainerCallback):\n",
        "    def __init__(self, trainer, eval_dataset, early_stopping_patience=5):\n",
        "        self.trainer = trainer\n",
        "        self.eval_dataset = eval_dataset\n",
        "        self.early_stopping_patience = early_stopping_patience\n",
        "        self.best_loss = float('inf')\n",
        "        self.patience_counter = 0\n",
        "        self.incorrect_samples = []\n",
        "\n",
        "    def on_evaluate(self, args, state, control, **kwargs):\n",
        "        eval_loss = kwargs.get('metrics', {}).get('eval_loss')\n",
        "\n",
        "        if eval_loss is not None:\n",
        "            if eval_loss < self.best_loss:\n",
        "                self.best_loss = eval_loss\n",
        "                self.patience_counter = 0\n",
        "            else:\n",
        "                self.patience_counter += 1\n",
        "\n",
        "            if self.patience_counter >= self.early_stopping_patience:\n",
        "                print(f\"No improvement in {self.early_stopping_patience} evaluation steps. Stopping training early.\")\n",
        "                control.should_training_stop = True\n",
        "\n",
        "        eval_dataloader = self.trainer.get_eval_dataloader(self.eval_dataset)\n",
        "        self.trainer.model.eval()\n",
        "        for batch in eval_dataloader:\n",
        "            batch = {k: v.to(self.trainer.args.device) for k, v in batch.items()}\n",
        "            with torch.no_grad():\n",
        "                outputs = self.trainer.model(**batch)\n",
        "                predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "                labels = batch['labels']\n",
        "                incorrect_mask = predictions != labels\n",
        "\n",
        "            if incorrect_mask.any():\n",
        "                incorrect_samples = {k: v[incorrect_mask].cpu().numpy() for k, v in batch.items()}\n",
        "                self.incorrect_samples.append(incorrect_samples)\n",
        "\n",
        "        print(\"Collected incorrect predictions for further analysis.\")"
      ],
      "metadata": {
        "id": "cGJBhiFPbOkl"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 공간 정의 함수\n",
        "def hp_space(trial):\n",
        "    return {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 5e-5, log=True),\n",
        "        'per_device_train_batch_size': trial.suggest_categorical('per_device_train_batch_size', [16, 32]),\n",
        "    }"
      ],
      "metadata": {
        "id": "I3wkL9iGbOiW"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 초기화 함수 정의\n",
        "def model_init():\n",
        "    return AutoModelForSequenceClassification.from_pretrained(\"microsoft/graphcodebert-base\", num_labels=9)"
      ],
      "metadata": {
        "id": "yqFT8zH0bOfu"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TrainingArguments 설정\n",
        "batch_size = 16\n",
        "epoch_num = 1000\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=epoch_num,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=500,\n",
        "    logging_dir='./logs',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='eval_loss',\n",
        "    fp16=True  # 혼합 정밀도 사용\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PkpKC-obOea",
        "outputId": "8ad49a6a-a4ea-40f0-c3e1-316f884ebf8b"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 커스텀 트레이너 정의\n",
        "class CustomTrainer(Trainer):\n",
        "    def create_optimizer_and_scheduler(self, num_training_steps):\n",
        "        self.optimizer = torch.optim.AdamW(\n",
        "            self.model.parameters(),\n",
        "            lr=learning_rate,\n",
        "            betas=(0.9, 0.99),\n",
        "            eps=1e-8,\n",
        "            weight_decay=0.1\n",
        "        )\n",
        "        self.lr_scheduler = get_cosine_schedule_with_warmup(\n",
        "            self.optimizer,\n",
        "            num_warmup_steps=5,\n",
        "            num_training_steps=num_training_steps\n",
        "        )"
      ],
      "metadata": {
        "id": "cjEhkdz9f2ox"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 트레이너 초기화\n",
        "trainer = CustomTrainer(\n",
        "    model_init=model_init,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_dataset['train'],\n",
        "    eval_dataset=encoded_dataset['test'],\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=data_collator,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "citNljredvV-",
        "outputId": "430367b6-6769-4513-80ee-17b6c8c0cad6"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 콜백 인스턴스 생성\n",
        "callback = CustomTrainerCallback(trainer, eval_dataset=encoded_dataset['test'], early_stopping_patience=5)\n",
        "trainer.add_callback(callback)"
      ],
      "metadata": {
        "id": "rpwHZG7cbOZn"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optuna와 트레이너 통합\n",
        "best_run = trainer.hyperparameter_search(direction=\"maximize\", n_trials=9, hp_space=hp_space)\n",
        "\n",
        "print(best_run)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Gxei1FGibOWO",
        "outputId": "f64c5068-8cfb-4a53-d708-b09d8d57fcaa"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-20 05:35:45,411] A new study created in memory with name: no-name-053bf34c-ebc2-4664-91f4-308f0d0d5ba3\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4000' max='401000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  4000/401000 19:08 < 31:39:59, 3.48 it/s, Epoch 9/1000]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Class 0</th>\n",
              "      <th>F1 Class 1</th>\n",
              "      <th>F1 Class 2</th>\n",
              "      <th>F1 Class 3</th>\n",
              "      <th>F1 Class 4</th>\n",
              "      <th>F1 Class 5</th>\n",
              "      <th>F1 Class 6</th>\n",
              "      <th>F1 Class 7</th>\n",
              "      <th>F1 Class 8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.412200</td>\n",
              "      <td>0.928899</td>\n",
              "      <td>0.694813</td>\n",
              "      <td>0.694813</td>\n",
              "      <td>0.697539</td>\n",
              "      <td>0.697531</td>\n",
              "      <td>0.694813</td>\n",
              "      <td>0.463987</td>\n",
              "      <td>0.523480</td>\n",
              "      <td>0.959307</td>\n",
              "      <td>0.705986</td>\n",
              "      <td>0.683417</td>\n",
              "      <td>0.713781</td>\n",
              "      <td>0.682264</td>\n",
              "      <td>0.842893</td>\n",
              "      <td>0.702663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.663100</td>\n",
              "      <td>0.632293</td>\n",
              "      <td>0.809099</td>\n",
              "      <td>0.809099</td>\n",
              "      <td>0.805918</td>\n",
              "      <td>0.806080</td>\n",
              "      <td>0.809099</td>\n",
              "      <td>0.589767</td>\n",
              "      <td>0.696270</td>\n",
              "      <td>0.967687</td>\n",
              "      <td>0.763791</td>\n",
              "      <td>0.805893</td>\n",
              "      <td>0.834043</td>\n",
              "      <td>0.854305</td>\n",
              "      <td>0.913561</td>\n",
              "      <td>0.829408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.321900</td>\n",
              "      <td>0.497690</td>\n",
              "      <td>0.858781</td>\n",
              "      <td>0.858781</td>\n",
              "      <td>0.858706</td>\n",
              "      <td>0.858773</td>\n",
              "      <td>0.858781</td>\n",
              "      <td>0.662162</td>\n",
              "      <td>0.776527</td>\n",
              "      <td>0.962406</td>\n",
              "      <td>0.851644</td>\n",
              "      <td>0.831731</td>\n",
              "      <td>0.869286</td>\n",
              "      <td>0.920875</td>\n",
              "      <td>0.936893</td>\n",
              "      <td>0.917431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.173000</td>\n",
              "      <td>0.509730</td>\n",
              "      <td>0.876069</td>\n",
              "      <td>0.876069</td>\n",
              "      <td>0.878644</td>\n",
              "      <td>0.878908</td>\n",
              "      <td>0.876069</td>\n",
              "      <td>0.682643</td>\n",
              "      <td>0.799665</td>\n",
              "      <td>0.970662</td>\n",
              "      <td>0.889267</td>\n",
              "      <td>0.892035</td>\n",
              "      <td>0.882927</td>\n",
              "      <td>0.932331</td>\n",
              "      <td>0.936342</td>\n",
              "      <td>0.924303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.106500</td>\n",
              "      <td>0.626540</td>\n",
              "      <td>0.875887</td>\n",
              "      <td>0.875887</td>\n",
              "      <td>0.875622</td>\n",
              "      <td>0.875822</td>\n",
              "      <td>0.875887</td>\n",
              "      <td>0.704762</td>\n",
              "      <td>0.808950</td>\n",
              "      <td>0.945573</td>\n",
              "      <td>0.889077</td>\n",
              "      <td>0.885305</td>\n",
              "      <td>0.869767</td>\n",
              "      <td>0.921927</td>\n",
              "      <td>0.928296</td>\n",
              "      <td>0.928743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.084600</td>\n",
              "      <td>0.656838</td>\n",
              "      <td>0.875159</td>\n",
              "      <td>0.875159</td>\n",
              "      <td>0.874546</td>\n",
              "      <td>0.874663</td>\n",
              "      <td>0.875159</td>\n",
              "      <td>0.688042</td>\n",
              "      <td>0.798707</td>\n",
              "      <td>0.964492</td>\n",
              "      <td>0.841328</td>\n",
              "      <td>0.878216</td>\n",
              "      <td>0.894389</td>\n",
              "      <td>0.927973</td>\n",
              "      <td>0.945161</td>\n",
              "      <td>0.933661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.072000</td>\n",
              "      <td>0.687689</td>\n",
              "      <td>0.875341</td>\n",
              "      <td>0.875341</td>\n",
              "      <td>0.874740</td>\n",
              "      <td>0.874897</td>\n",
              "      <td>0.875341</td>\n",
              "      <td>0.685761</td>\n",
              "      <td>0.807993</td>\n",
              "      <td>0.969748</td>\n",
              "      <td>0.893476</td>\n",
              "      <td>0.869276</td>\n",
              "      <td>0.886400</td>\n",
              "      <td>0.913183</td>\n",
              "      <td>0.946852</td>\n",
              "      <td>0.901387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.064100</td>\n",
              "      <td>0.700016</td>\n",
              "      <td>0.879345</td>\n",
              "      <td>0.879345</td>\n",
              "      <td>0.879157</td>\n",
              "      <td>0.879208</td>\n",
              "      <td>0.879345</td>\n",
              "      <td>0.704731</td>\n",
              "      <td>0.812870</td>\n",
              "      <td>0.970563</td>\n",
              "      <td>0.894737</td>\n",
              "      <td>0.861514</td>\n",
              "      <td>0.888152</td>\n",
              "      <td>0.910267</td>\n",
              "      <td>0.946098</td>\n",
              "      <td>0.923939</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collected incorrect predictions for further analysis.\n",
            "Collected incorrect predictions for further analysis.\n",
            "Collected incorrect predictions for further analysis.\n",
            "Collected incorrect predictions for further analysis.\n",
            "Collected incorrect predictions for further analysis.\n",
            "Collected incorrect predictions for further analysis.\n",
            "Collected incorrect predictions for further analysis.\n",
            "No improvement in 5 evaluation steps. Stopping training early.\n",
            "Collected incorrect predictions for further analysis.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-20 05:54:54,714] Trial 0 finished with value: 12.309271117607663 and parameters: {'learning_rate': 2.9450983567105204e-05, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 12.309271117607663.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='802000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   500/802000 01:34 < 42:12:33, 5.27 it/s, Epoch 0/1000]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Class 0</th>\n",
              "      <th>F1 Class 1</th>\n",
              "      <th>F1 Class 2</th>\n",
              "      <th>F1 Class 3</th>\n",
              "      <th>F1 Class 4</th>\n",
              "      <th>F1 Class 5</th>\n",
              "      <th>F1 Class 6</th>\n",
              "      <th>F1 Class 7</th>\n",
              "      <th>F1 Class 8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.572700</td>\n",
              "      <td>1.204315</td>\n",
              "      <td>0.589809</td>\n",
              "      <td>0.589809</td>\n",
              "      <td>0.571257</td>\n",
              "      <td>0.571183</td>\n",
              "      <td>0.589809</td>\n",
              "      <td>0.295400</td>\n",
              "      <td>0.341401</td>\n",
              "      <td>0.932994</td>\n",
              "      <td>0.498316</td>\n",
              "      <td>0.516841</td>\n",
              "      <td>0.643564</td>\n",
              "      <td>0.603878</td>\n",
              "      <td>0.743750</td>\n",
              "      <td>0.564506</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement in 5 evaluation steps. Stopping training early.\n",
            "Collected incorrect predictions for further analysis.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-20 05:56:30,713] Trial 1 finished with value: 8.052518402266854 and parameters: {'learning_rate': 1.4576617062990481e-05, 'per_device_train_batch_size': 16}. Best is trial 0 with value: 12.309271117607663.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='401000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   500/401000 02:23 < 32:04:07, 3.47 it/s, Epoch 1/1000]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Class 0</th>\n",
              "      <th>F1 Class 1</th>\n",
              "      <th>F1 Class 2</th>\n",
              "      <th>F1 Class 3</th>\n",
              "      <th>F1 Class 4</th>\n",
              "      <th>F1 Class 5</th>\n",
              "      <th>F1 Class 6</th>\n",
              "      <th>F1 Class 7</th>\n",
              "      <th>F1 Class 8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.412200</td>\n",
              "      <td>0.928899</td>\n",
              "      <td>0.694813</td>\n",
              "      <td>0.694813</td>\n",
              "      <td>0.697539</td>\n",
              "      <td>0.697531</td>\n",
              "      <td>0.694813</td>\n",
              "      <td>0.463987</td>\n",
              "      <td>0.523480</td>\n",
              "      <td>0.959307</td>\n",
              "      <td>0.705986</td>\n",
              "      <td>0.683417</td>\n",
              "      <td>0.713781</td>\n",
              "      <td>0.682264</td>\n",
              "      <td>0.842893</td>\n",
              "      <td>0.702663</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement in 5 evaluation steps. Stopping training early.\n",
            "Collected incorrect predictions for further analysis.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-20 05:58:55,551] Trial 2 finished with value: 9.757287432737039 and parameters: {'learning_rate': 2.3877847445879708e-05, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 12.309271117607663.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='401000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   500/401000 02:23 < 32:06:50, 3.46 it/s, Epoch 1/1000]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Class 0</th>\n",
              "      <th>F1 Class 1</th>\n",
              "      <th>F1 Class 2</th>\n",
              "      <th>F1 Class 3</th>\n",
              "      <th>F1 Class 4</th>\n",
              "      <th>F1 Class 5</th>\n",
              "      <th>F1 Class 6</th>\n",
              "      <th>F1 Class 7</th>\n",
              "      <th>F1 Class 8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.412200</td>\n",
              "      <td>0.928899</td>\n",
              "      <td>0.694813</td>\n",
              "      <td>0.694813</td>\n",
              "      <td>0.697539</td>\n",
              "      <td>0.697531</td>\n",
              "      <td>0.694813</td>\n",
              "      <td>0.463987</td>\n",
              "      <td>0.523480</td>\n",
              "      <td>0.959307</td>\n",
              "      <td>0.705986</td>\n",
              "      <td>0.683417</td>\n",
              "      <td>0.713781</td>\n",
              "      <td>0.682264</td>\n",
              "      <td>0.842893</td>\n",
              "      <td>0.702663</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement in 5 evaluation steps. Stopping training early.\n",
            "Collected incorrect predictions for further analysis.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-20 06:01:20,564] Trial 3 finished with value: 9.757287432737039 and parameters: {'learning_rate': 1.567633442274779e-05, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 12.309271117607663.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='401000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   500/401000 02:24 < 32:10:35, 3.46 it/s, Epoch 1/1000]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Class 0</th>\n",
              "      <th>F1 Class 1</th>\n",
              "      <th>F1 Class 2</th>\n",
              "      <th>F1 Class 3</th>\n",
              "      <th>F1 Class 4</th>\n",
              "      <th>F1 Class 5</th>\n",
              "      <th>F1 Class 6</th>\n",
              "      <th>F1 Class 7</th>\n",
              "      <th>F1 Class 8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.412200</td>\n",
              "      <td>0.928899</td>\n",
              "      <td>0.694813</td>\n",
              "      <td>0.694813</td>\n",
              "      <td>0.697539</td>\n",
              "      <td>0.697531</td>\n",
              "      <td>0.694813</td>\n",
              "      <td>0.463987</td>\n",
              "      <td>0.523480</td>\n",
              "      <td>0.959307</td>\n",
              "      <td>0.705986</td>\n",
              "      <td>0.683417</td>\n",
              "      <td>0.713781</td>\n",
              "      <td>0.682264</td>\n",
              "      <td>0.842893</td>\n",
              "      <td>0.702663</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement in 5 evaluation steps. Stopping training early.\n",
            "Collected incorrect predictions for further analysis.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-20 06:03:45,967] Trial 4 finished with value: 9.757287432737039 and parameters: {'learning_rate': 1.7727013790037822e-05, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 12.309271117607663.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='401000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   500/401000 02:23 < 32:10:01, 3.46 it/s, Epoch 1/1000]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Class 0</th>\n",
              "      <th>F1 Class 1</th>\n",
              "      <th>F1 Class 2</th>\n",
              "      <th>F1 Class 3</th>\n",
              "      <th>F1 Class 4</th>\n",
              "      <th>F1 Class 5</th>\n",
              "      <th>F1 Class 6</th>\n",
              "      <th>F1 Class 7</th>\n",
              "      <th>F1 Class 8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.412200</td>\n",
              "      <td>0.928899</td>\n",
              "      <td>0.694813</td>\n",
              "      <td>0.694813</td>\n",
              "      <td>0.697539</td>\n",
              "      <td>0.697531</td>\n",
              "      <td>0.694813</td>\n",
              "      <td>0.463987</td>\n",
              "      <td>0.523480</td>\n",
              "      <td>0.959307</td>\n",
              "      <td>0.705986</td>\n",
              "      <td>0.683417</td>\n",
              "      <td>0.713781</td>\n",
              "      <td>0.682264</td>\n",
              "      <td>0.842893</td>\n",
              "      <td>0.702663</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement in 5 evaluation steps. Stopping training early.\n",
            "Collected incorrect predictions for further analysis.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-20 06:06:11,274] Trial 5 finished with value: 9.757287432737039 and parameters: {'learning_rate': 1.4714951126840009e-05, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 12.309271117607663.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='401000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   500/401000 02:23 < 32:06:01, 3.47 it/s, Epoch 1/1000]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Class 0</th>\n",
              "      <th>F1 Class 1</th>\n",
              "      <th>F1 Class 2</th>\n",
              "      <th>F1 Class 3</th>\n",
              "      <th>F1 Class 4</th>\n",
              "      <th>F1 Class 5</th>\n",
              "      <th>F1 Class 6</th>\n",
              "      <th>F1 Class 7</th>\n",
              "      <th>F1 Class 8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.412200</td>\n",
              "      <td>0.928899</td>\n",
              "      <td>0.694813</td>\n",
              "      <td>0.694813</td>\n",
              "      <td>0.697539</td>\n",
              "      <td>0.697531</td>\n",
              "      <td>0.694813</td>\n",
              "      <td>0.463987</td>\n",
              "      <td>0.523480</td>\n",
              "      <td>0.959307</td>\n",
              "      <td>0.705986</td>\n",
              "      <td>0.683417</td>\n",
              "      <td>0.713781</td>\n",
              "      <td>0.682264</td>\n",
              "      <td>0.842893</td>\n",
              "      <td>0.702663</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement in 5 evaluation steps. Stopping training early.\n",
            "Collected incorrect predictions for further analysis.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-20 06:08:36,633] Trial 6 finished with value: 9.757287432737039 and parameters: {'learning_rate': 2.0460280161614737e-05, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 12.309271117607663.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='802000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   500/802000 01:32 < 41:21:21, 5.38 it/s, Epoch 0/1000]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Class 0</th>\n",
              "      <th>F1 Class 1</th>\n",
              "      <th>F1 Class 2</th>\n",
              "      <th>F1 Class 3</th>\n",
              "      <th>F1 Class 4</th>\n",
              "      <th>F1 Class 5</th>\n",
              "      <th>F1 Class 6</th>\n",
              "      <th>F1 Class 7</th>\n",
              "      <th>F1 Class 8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.572700</td>\n",
              "      <td>1.204315</td>\n",
              "      <td>0.589809</td>\n",
              "      <td>0.589809</td>\n",
              "      <td>0.571257</td>\n",
              "      <td>0.571183</td>\n",
              "      <td>0.589809</td>\n",
              "      <td>0.295400</td>\n",
              "      <td>0.341401</td>\n",
              "      <td>0.932994</td>\n",
              "      <td>0.498316</td>\n",
              "      <td>0.516841</td>\n",
              "      <td>0.643564</td>\n",
              "      <td>0.603878</td>\n",
              "      <td>0.743750</td>\n",
              "      <td>0.564506</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement in 5 evaluation steps. Stopping training early.\n",
            "Collected incorrect predictions for further analysis.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-20 06:10:10,390] Trial 7 pruned. \n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='802000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   500/802000 01:32 < 41:16:43, 5.39 it/s, Epoch 0/1000]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Class 0</th>\n",
              "      <th>F1 Class 1</th>\n",
              "      <th>F1 Class 2</th>\n",
              "      <th>F1 Class 3</th>\n",
              "      <th>F1 Class 4</th>\n",
              "      <th>F1 Class 5</th>\n",
              "      <th>F1 Class 6</th>\n",
              "      <th>F1 Class 7</th>\n",
              "      <th>F1 Class 8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.572700</td>\n",
              "      <td>1.204315</td>\n",
              "      <td>0.589809</td>\n",
              "      <td>0.589809</td>\n",
              "      <td>0.571257</td>\n",
              "      <td>0.571183</td>\n",
              "      <td>0.589809</td>\n",
              "      <td>0.295400</td>\n",
              "      <td>0.341401</td>\n",
              "      <td>0.932994</td>\n",
              "      <td>0.498316</td>\n",
              "      <td>0.516841</td>\n",
              "      <td>0.643564</td>\n",
              "      <td>0.603878</td>\n",
              "      <td>0.743750</td>\n",
              "      <td>0.564506</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement in 5 evaluation steps. Stopping training early.\n",
            "Collected incorrect predictions for further analysis.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-20 06:11:43,943] Trial 8 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BestRun(run_id='0', objective=12.309271117607663, hyperparameters={'learning_rate': 2.9450983567105204e-05, 'per_device_train_batch_size': 32}, run_summary=None)\n"
          ]
        }
      ]
    }
  ]
}